/*
 * Copyright (c) 2024 Space-RF.org
 * Copyright (c) 2024 Chiradip Mandal
 * 
 * DB25 SQL Parser - Implementation
 */

#include "db25/parser/parser.hpp"
#include <cstdlib>  // for std::abort
#include <cstring>  // for std::memcpy
#include <iostream> // for std::cerr (debug output)
#include <stdexcept> // for std::runtime_error

namespace db25::parser {

// ========== Construction ==========

Parser::Parser(const ParserConfig& config)
    : config_(config)
    , arena_(64 * 1024)  // 64KB initial size
    // input_ is default-initialized (empty string_view)
    , current_depth_(0)
    , next_node_id_(1)
    , tokenizer_(nullptr)
    , current_token_(nullptr)
    , peek_token_(nullptr)
    , parenthesis_depth_(0)  // Initialize parenthesis tracking
    , strict_mode_(true) {   // Enable strict validation by default
}

Parser::~Parser() {
    delete tokenizer_;  // Safe even if nullptr
}

// ========== Helper Methods ==========

// Helper to copy a string to the arena and return a string_view
// This eliminates repetitive string copying code throughout the parser
std::string_view Parser::copy_to_arena(std::string_view source) {
    if (source.empty()) {
        return {};
    }
    const size_t length = source.length();
    // Note: arena_memory is NOT a local variable - it's a pointer to heap memory
    // managed by the arena allocator. This memory persists until arena.reset()
    char* const arena_memory = static_cast<char*>(arena_.allocate(length + 1));
    std::memcpy(arena_memory, source.data(), length);
    arena_memory[length] = '\0';
    // Returning a view of arena-managed memory is safe - the memory lifetime
    // is tied to the Parser object, not this function scope
    return {arena_memory, length};
}

// ========== Main Interface ==========

ParseResult Parser::parse(std::string_view sql) {
    // Reset state
    reset();
    input_ = sql;
    
    // Initialize tokenizer
    tokenizer_ = new tokenizer::Tokenizer(sql);
    current_token_ = tokenizer_->current();
    peek_token_ = tokenizer_->peek();
    
    // Check for empty input
    if (!current_token_ || current_token_->type == tokenizer::TokenType::EndOfFile) {
        delete tokenizer_;
        tokenizer_ = nullptr;
        return std::unexpected(ParseError{
            1, 1, 0,
            "Empty SQL statement",
            sql.substr(0, 50)
        });
    }
    
    // Parse the statement
    ast::ASTNode* root = parse_statement();
    
    // Check if depth was exceeded
    if (depth_exceeded_) {
        uint32_t line = current_token_ ? current_token_->line : 1;
        uint32_t col = current_token_ ? current_token_->column : 1;
        uint32_t pos = tokenizer_ ? tokenizer_->position() : 0;
        delete tokenizer_;
        tokenizer_ = nullptr;
        return std::unexpected(ParseError{
            line, col, pos,
            "Maximum recursion depth exceeded",
            sql.substr(0, 50)
        });
    }
    
    if (!root) {
        uint32_t line = current_token_ ? current_token_->line : 1;
        uint32_t col = current_token_ ? current_token_->column : 1;
        uint32_t pos = tokenizer_ ? tokenizer_->position() : 0;  // Get position BEFORE delete
        delete tokenizer_;
        tokenizer_ = nullptr;
        return std::unexpected(ParseError{
            line, col,
            pos,
            "Failed to parse statement",
            sql.substr(0, 50)
        });
    }
    
    // Check for unbalanced parentheses
    if (parenthesis_depth_ != 0) {
        uint32_t line = current_token_ ? current_token_->line : 1;
        uint32_t col = current_token_ ? current_token_->column : 1;
        uint32_t pos = tokenizer_ ? tokenizer_->position() : 0;
        delete tokenizer_;
        tokenizer_ = nullptr;
        return std::unexpected(ParseError{
            line, col, pos,
            parenthesis_depth_ > 0 ? "Unclosed parenthesis" : "Unexpected closing parenthesis",
            sql.substr(0, 50)
        });
    }
    
    // Validate AST if in strict mode
    if (strict_mode_ && !validate_ast(root)) {
        uint32_t line = current_token_ ? current_token_->line : 1;
        uint32_t col = current_token_ ? current_token_->column : 1;
        uint32_t pos = tokenizer_ ? tokenizer_->position() : 0;
        delete tokenizer_;
        tokenizer_ = nullptr;
        return std::unexpected(ParseError{
            line, col, pos,
            "Invalid SQL: validation failed",
            sql.substr(0, 50)
        });
    }
    
    // Don't delete tokenizer on success - the AST nodes have string_views
    // pointing to the tokenizer's memory. The tokenizer will be deleted
    // when the parser is destroyed or reset() is called.
    // delete tokenizer_;  // KEEP ALIVE for AST string_views
    // tokenizer_ = nullptr;
    return root;
}

std::expected<std::vector<ast::ASTNode*>, ParseError>
Parser::parse_script(std::string_view sql [[maybe_unused]]) {
    std::vector<ast::ASTNode*> statements;
    
    // TODO: Parse multiple statements separated by semicolons
    
    return statements;
}

// ========== Memory Management ==========

void Parser::reset() {
    arena_.reset();
    current_depth_ = 0;
    next_node_id_ = 1;
    parenthesis_depth_ = 0;  // Reset parenthesis tracking
    depth_exceeded_ = false;  // Reset depth exceeded flag
    delete tokenizer_;  // Safe even if nullptr
    tokenizer_ = nullptr;
    current_token_ = nullptr;
    peek_token_ = nullptr;
}

size_t Parser::get_memory_used() const noexcept {
    return arena_.bytes_used();
}

size_t Parser::get_node_count() const noexcept {
    return next_node_id_ - 1;
}

// ========== Token Stream ==========

void Parser::advance() {
    if (tokenizer_ && !tokenizer_->at_end()) {
        tokenizer_->advance();
        current_token_ = tokenizer_->current();
        peek_token_ = tokenizer_->peek();
    }
}

bool Parser::match(int token_type) {
    if (check(token_type)) {
        advance();
        return true;
    }
    return false;
}

bool Parser::check(int token_type) const {
    return current_token_ && 
           static_cast<int>(current_token_->type) == token_type;
}

void Parser::consume(int token_type, const char* message) {
    if (!match(token_type)) {
        error(message);
    }
}

// ========== Recursive Descent Parsers ==========

ast::ASTNode* Parser::parse_statement() {
    if (!current_token_) {
        return nullptr;
    }
    
    // Prefetch tokens for statement dispatch
    // Statement parsing needs to look ahead for statement type determination
    if (tokenizer_) {
        const auto& tokens = tokenizer_->get_tokens();
        size_t pos = tokenizer_->position();
        
        // Prefetch next 3 tokens for compound statement detection (CREATE TABLE, DROP INDEX, etc.)
        if (pos + 1 < tokens.size()) __builtin_prefetch(&tokens[pos + 1], 0, 3);
        if (pos + 2 < tokens.size()) __builtin_prefetch(&tokens[pos + 2], 0, 2);
        if (pos + 3 < tokens.size()) __builtin_prefetch(&tokens[pos + 3], 0, 1);
    }
    
    // Check if it's a keyword or identifier (some DDL keywords like TRUNCATE aren't in the keyword list)
    if (current_token_->type != tokenizer::TokenType::Keyword && 
        current_token_->type != tokenizer::TokenType::Identifier) {
        return nullptr;
    }
    
    // Dispatch based on keyword/identifier value
    // Note: Some DDL statements like TRUNCATE are not in the keyword list
    std::string_view keyword = current_token_->value;
    
    // Convert to uppercase for comparison (tokenizer may preserve case)
    if (keyword == "WITH" || keyword == "with") {
        // Parse CTE and the following statement
        return parse_with_statement();
    } else if (keyword == "SELECT" || keyword == "select") {
        return parse_select_stmt();
    } else if (keyword == "INSERT" || keyword == "insert") {
        return parse_insert_stmt();
    } else if (keyword == "UPDATE" || keyword == "update") {
        return parse_update_stmt();
    } else if (keyword == "DELETE" || keyword == "delete") {
        return parse_delete_stmt();
    } else if (keyword == "CREATE" || keyword == "create") {
        // Dispatch to appropriate CREATE handler
        return parse_create_stmt();
    } else if (keyword == "DROP" || keyword == "drop") {
        return parse_drop_stmt();
    } else if (keyword == "ALTER" || keyword == "alter") {
        return parse_alter_table_stmt();
    } else if (keyword == "TRUNCATE" || keyword == "truncate") {
        return parse_truncate_stmt();
    }
    
    return nullptr;
}

ast::ASTNode* Parser::parse_with_statement() {
    DepthGuard guard(this);  // Protect against deep recursion
    if (!guard.is_valid()) return nullptr;
    
    // Consume WITH keyword
    advance();
    
    // Create CTE clause node
    auto* cte_clause = arena_.allocate<ast::ASTNode>();
    new (cte_clause) ast::ASTNode(ast::NodeType::CTEClause);
    cte_clause->node_id = next_node_id_++;
    
    // Check for RECURSIVE
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        current_token_->keyword_id == db25::Keyword::RECURSIVE) {
        cte_clause->flags = cte_clause->flags | ast::NodeFlags::IsRecursive;  // Set RECURSIVE flag
        advance();
#ifdef DEBUG_CTE
        if (current_token_) {
            std::cerr << "After RECURSIVE, token: " << current_token_->value 
                      << " type: " << static_cast<int>(current_token_->type) << std::endl;
        }
#endif
    }
    
    // Parse CTE definitions
    ast::ASTNode* first_cte = nullptr;
    ast::ASTNode* last_cte = nullptr;
    
    do {
        // Parse CTE name
        if (!current_token_) {
            error("Unexpected end of input - expected CTE name after WITH [RECURSIVE]");
#ifdef DEBUG_CTE
            // No current token for CTE name
#endif
            return nullptr;
        }
        if (current_token_->type != tokenizer::TokenType::Identifier) {
            std::string err_msg = "Expected CTE name (identifier) after WITH [RECURSIVE], but got ";
            err_msg += "token type " + std::to_string(static_cast<int>(current_token_->type));
            err_msg += " with value '" + std::string(current_token_->value) + "'";
            error(err_msg);
#ifdef DEBUG_CTE
            // std::cerr << "DEBUG: Wrong token type for CTE name: " << static_cast<int>(current_token_->type) << std::endl;
#endif
            return nullptr;  // CTE name required
        }
        
        auto* cte_def = arena_.allocate<ast::ASTNode>();
        new (cte_def) ast::ASTNode(ast::NodeType::CTEDefinition);
        cte_def->node_id = next_node_id_++;
        cte_def->primary_text = copy_to_arena(current_token_->value);
#ifdef DEBUG_CTE
        // std::cerr << "DEBUG: Parsed CTE name: " << cte_def->primary_text << std::endl;
#endif
        advance();
        
        // Check for optional column list OR AS keyword
        // After CTE name, we can have:
        //   1. (column, list) AS (query)
        //   2. AS (query)
        
        if (current_token_ && current_token_->value == "(") {
#ifdef DEBUG_CTE
            // std::cerr << "DEBUG: Found '(' after CTE name" << std::endl;
#endif
            // Option 1: Column list
            advance();  // consume '('
            parenthesis_depth_++;
            
            // Check if this is a column list by looking for identifier
            if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier) {
#ifdef DEBUG_CTE
                // std::cerr << "DEBUG: Parsing column list" << std::endl;
#endif
                // Parse column list
                auto* col_list = arena_.allocate<ast::ASTNode>();
                new (col_list) ast::ASTNode(ast::NodeType::ColumnList);
                col_list->node_id = next_node_id_++;
                col_list->parent = cte_def;
                
                ast::ASTNode* first_col = nullptr;
                ast::ASTNode* last_col = nullptr;
                
                // Parse column names
                do {
                    auto* col_node = arena_.allocate<ast::ASTNode>();
                    new (col_node) ast::ASTNode(ast::NodeType::Identifier);
                    col_node->node_id = next_node_id_++;
                    col_node->primary_text = copy_to_arena(current_token_->value);
                    col_node->parent = col_list;
                    
                    if (!first_col) {
                        first_col = col_node;
                        col_list->first_child = first_col;
                    } else {
                        last_col->next_sibling = col_node;
                    }
                    last_col = col_node;
                    col_list->child_count++;
                    
                    advance();
                    
                    // Check for comma
                    if (current_token_ && current_token_->value == ",") {
                        advance();
                    } else {
                        break;
                    }
                } while (current_token_ && current_token_->type == tokenizer::TokenType::Identifier);
                
                // Consume closing paren
                if (current_token_ && current_token_->value == ")") {
                    advance();  // consume ')'
                    parenthesis_depth_--;
                } else {
                    error("Expected ')' after column list");
                    return nullptr;
                }
                
                // Add column list to CTE definition
                cte_def->first_child = col_list;
                cte_def->child_count = 1;
                
                // Now expect AS keyword after column list
                if (!current_token_ || current_token_->type != tokenizer::TokenType::Keyword ||
                    (current_token_->value != "AS" && current_token_->value != "as")) {
                    error("Expected AS after column list in CTE definition");
                    return nullptr;
                }
                advance();  // consume AS
                
                // Expect '(' for the query
                if (!current_token_ || current_token_->value != "(") {
                    error("Expected '(' after AS in CTE definition");
                    return nullptr;
                }
                advance();  // consume '('
                parenthesis_depth_++;
            } else {
                // Not a column list - we have '(' but it's not followed by identifier
                // This '(' must be the start of the query itself (e.g., "(SELECT ...)")
                // We're already inside the paren
            }
        } else if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                   current_token_->keyword_id == db25::Keyword::AS) {
#ifdef DEBUG_CTE
            // std::cerr << "DEBUG: Found AS after CTE name" << std::endl;
#endif
            // Option 2: No column list, just AS
            advance();  // consume AS
            
            // Expect '(' for the query
            if (!current_token_ || current_token_->value != "(") {
                error("Expected '(' after AS in CTE definition");
                return nullptr;
            }
#ifdef DEBUG_CTE
            // std::cerr << "DEBUG: Found '(' after AS, consuming it" << std::endl;
#endif
            advance();  // consume '('
            parenthesis_depth_++;
            
        } else {
            error("Expected '(' or AS after CTE name");
#ifdef DEBUG_CTE
            if (current_token_) {
                // std::cerr << "DEBUG: Unexpected token after CTE name: " << current_token_->value 
                //           << " type: " << static_cast<int>(current_token_->type) << std::endl;
            }
#endif
            return nullptr;
        }
        
        // At this point, we should be inside the CTE query parentheses
        
        // Parse the CTE query (could be SELECT or WITH for nested CTEs)
        ast::ASTNode* cte_query = nullptr;
#ifdef DEBUG_CTE
        // std::cerr << "DEBUG: About to parse CTE query. Current token: ";
        if (current_token_) {
            std::cerr << current_token_->value << " type: " << static_cast<int>(current_token_->type);
        }
        std::cerr << std::endl;
#endif
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
            if (current_token_->keyword_id == db25::Keyword::SELECT) {
#ifdef DEBUG_CTE
                // std::cerr << "DEBUG: Parsing SELECT in CTE" << std::endl;
#endif
                cte_query = parse_select_stmt();
                // parse_select_stmt might return a UNION/INTERSECT/EXCEPT node
                // That's fine for CTEs, especially recursive ones
            } else if (current_token_->keyword_id == db25::Keyword::WITH) {
                cte_query = parse_with_statement();
            }
        }
        
        if (cte_query) {
            cte_query->parent = cte_def;
            if (cte_def->first_child) {
                // Already has column list
                cte_def->first_child->next_sibling = cte_query;
                cte_def->child_count++;
            } else {
                cte_def->first_child = cte_query;
                cte_def->child_count = 1;
            }
        }
        
        // Consume closing paren
        if (current_token_ && current_token_->value == ")") {
            if (parenthesis_depth_ > 0) parenthesis_depth_--;
            advance();
        } else {
            // If we don't find a closing paren, the CTE query might have consumed too much
            // This can happen if parse_select_stmt handles UNION incorrectly in a CTE context
            // For now, we'll continue anyway to see what token we're at
#ifdef DEBUG_CTE
            if (current_token_) {
                std::cerr << "WARNING: No closing paren after CTE query. Current token: " 
                          << current_token_->value << std::endl;
            }
#endif
        }
        
        // Add CTE definition to list
        cte_def->parent = cte_clause;
        if (!first_cte) {
            first_cte = cte_def;
            cte_clause->first_child = first_cte;
        } else {
            last_cte->next_sibling = cte_def;
        }
        last_cte = cte_def;
        cte_clause->child_count++;
        
        // Check for comma (more CTEs)
        if (current_token_ && current_token_->value == ",") {
            advance();
        } else {
            break;
        }
    } while (true);
    
    // Parse the main statement (SELECT, INSERT, UPDATE, DELETE)
    ast::ASTNode* main_stmt = nullptr;
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
        std::string_view keyword = current_token_->value;
        if (keyword == "SELECT" || keyword == "select") {
            main_stmt = parse_select_stmt();
        } else if (keyword == "INSERT" || keyword == "insert") {
            main_stmt = parse_insert_stmt();
        } else if (keyword == "UPDATE" || keyword == "update") {
            main_stmt = parse_update_stmt();
        } else if (keyword == "DELETE" || keyword == "delete") {
            main_stmt = parse_delete_stmt();
        }
    }
    
    if (!main_stmt) {
#ifdef DEBUG_CTE
        // std::cerr << "DEBUG: No main statement after CTE. Current token: ";
        if (current_token_) {
            std::cerr << current_token_->value << " type: " << static_cast<int>(current_token_->type);
        } else {
            std::cerr << "(null)";
        }
        std::cerr << std::endl;
#endif
        return nullptr;  // Main statement required after CTE
    }
    
    // Attach CTE clause to main statement
    cte_clause->next_sibling = main_stmt->first_child;
    main_stmt->first_child = cte_clause;
    cte_clause->parent = main_stmt;
    main_stmt->child_count++;
    
    return main_stmt;
}

ast::ASTNode* Parser::parse_select_stmt() {
    DepthGuard guard(this);  // Protect against deep recursion
    if (!guard.is_valid()) return nullptr;
    
    // Prefetch tokens for SELECT statement parsing
    // SELECT statements have predictable structure: SELECT [DISTINCT] columns FROM ...
    if (tokenizer_) {
        const auto& tokens = tokenizer_->get_tokens();
        size_t pos = tokenizer_->position();
        
        // Prefetch next 5 tokens for SELECT/DISTINCT/column detection
        if (pos + 1 < tokens.size()) __builtin_prefetch(&tokens[pos + 1], 0, 3);
        if (pos + 2 < tokens.size()) __builtin_prefetch(&tokens[pos + 2], 0, 3);
        if (pos + 3 < tokens.size()) __builtin_prefetch(&tokens[pos + 3], 0, 2);
        if (pos + 4 < tokens.size()) __builtin_prefetch(&tokens[pos + 4], 0, 2);
        if (pos + 5 < tokens.size()) __builtin_prefetch(&tokens[pos + 5], 0, 1);
    }
    
    // Consume SELECT keyword
    advance();  // We already checked it's SELECT in parse_statement()
    
    // Create SELECT statement node
    auto* select_node = arena_.allocate<ast::ASTNode>();
    new (select_node) ast::ASTNode(ast::NodeType::SelectStmt);
    select_node->node_id = next_node_id_++;
    
    // Check for DISTINCT or ALL
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
        if (current_token_->value == "DISTINCT" || current_token_->value == "distinct") {
            select_node->semantic_flags |= static_cast<uint16_t>(ast::NodeFlags::Distinct);
            advance(); // consume DISTINCT
        } else if (current_token_->value == "ALL" || current_token_->value == "all") {
            select_node->semantic_flags |= static_cast<uint16_t>(ast::NodeFlags::All);
            advance(); // consume ALL
        }
    }
    
    // Parse SELECT list
    auto* select_list = parse_select_list();
    if (!select_list) {
        // SELECT list is required
        return nullptr;
    }
    
    select_list->parent = select_node;
    select_node->first_child = select_list;
    select_node->child_count = 1;
    
    // Parse FROM clause
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        current_token_->keyword_id == db25::Keyword::FROM) {
        advance(); // consume FROM
        
        auto* from_clause = parse_from_clause();
        if (from_clause) {
            from_clause->parent = select_node;
            // Add as sibling to select_list
            select_list->next_sibling = from_clause;
            select_node->child_count++;
        }
    }
    
    // Parse WHERE clause
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        current_token_->keyword_id == db25::Keyword::WHERE) {
        advance(); // consume WHERE
        
        auto* where_clause = parse_where_clause();
        if (!where_clause) {
            // WHERE keyword was present but condition failed to parse
            return nullptr;  // Fail the entire SELECT statement
        }
        
        where_clause->parent = select_node;
        // Add to the end of child list
        auto* last_child = select_node->first_child;
        while (last_child->next_sibling) {
            last_child = last_child->next_sibling;
        }
        last_child->next_sibling = where_clause;
        select_node->child_count++;
    }
    
    // Parse GROUP BY clause
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "GROUP" || current_token_->value == "group")) {
        advance(); // consume GROUP
        if (current_token_ && (current_token_->value == "BY" || current_token_->value == "by")) {
            advance(); // consume BY
            
            auto* group_by = parse_group_by_clause();
            if (group_by) {
                group_by->parent = select_node;
                // Add to the end of child list
                auto* last_child = select_node->first_child;
                while (last_child->next_sibling) {
                    last_child = last_child->next_sibling;
                }
                last_child->next_sibling = group_by;
                select_node->child_count++;
            }
        }
    }
    
    // Parse HAVING clause
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "HAVING" || current_token_->value == "having")) {
        advance(); // consume HAVING
        
        auto* having_clause = parse_having_clause();
        if (having_clause) {
            having_clause->parent = select_node;
            // Add to the end of child list
            auto* last_child = select_node->first_child;
            while (last_child->next_sibling) {
                last_child = last_child->next_sibling;
            }
            last_child->next_sibling = having_clause;
            select_node->child_count++;
        }
    }
    
    // Parse ORDER BY clause
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "ORDER" || current_token_->value == "order")) {
        advance(); // consume ORDER
        if (current_token_ && (current_token_->value == "BY" || current_token_->value == "by")) {
            advance(); // consume BY
            
            auto* order_by = parse_order_by_clause();
            if (order_by) {
                order_by->parent = select_node;
                // Add to the end of child list
                auto* last_child = select_node->first_child;
                while (last_child->next_sibling) {
                    last_child = last_child->next_sibling;
                }
                last_child->next_sibling = order_by;
                select_node->child_count++;
            }
        }
    }
    
    // Parse LIMIT clause
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "LIMIT" || current_token_->value == "limit")) {
        advance(); // consume LIMIT
        
        auto* limit_clause = parse_limit_clause();
        if (limit_clause) {
            limit_clause->parent = select_node;
            // Add to the end of child list
            auto* last_child = select_node->first_child;
            while (last_child->next_sibling) {
                last_child = last_child->next_sibling;
            }
            last_child->next_sibling = limit_clause;
            select_node->child_count++;
        }
    }
    
    // Check for set operations (UNION, INTERSECT, EXCEPT)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
        std::string_view keyword = current_token_->value;
        if (keyword == "UNION" || keyword == "union" ||
            keyword == "INTERSECT" || keyword == "intersect" ||
            keyword == "EXCEPT" || keyword == "except" ||
            keyword == "MINUS" || keyword == "minus") {
            
            // Create set operation node
            ast::NodeType set_op_type;
            if (keyword == "UNION" || keyword == "union") {
                set_op_type = ast::NodeType::UnionStmt;
            } else if (keyword == "INTERSECT" || keyword == "intersect") {
                set_op_type = ast::NodeType::IntersectStmt;
            } else {
                set_op_type = ast::NodeType::ExceptStmt;
            }
            
            auto* set_op_node = arena_.allocate<ast::ASTNode>();
            new (set_op_node) ast::ASTNode(set_op_type);
            set_op_node->node_id = next_node_id_++;
            set_op_node->primary_text = copy_to_arena(keyword);
            
            advance(); // consume set operation keyword
            
            // Check for ALL
            if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                (current_token_->value == "ALL" || current_token_->value == "all")) {
                set_op_node->flags = set_op_node->flags | ast::NodeFlags::All;
                advance();
            }
            
            // Parse right-hand SELECT
            ast::ASTNode* right_select = nullptr;
            if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                (current_token_->value == "SELECT" || current_token_->value == "select")) {
                right_select = parse_select_stmt();
            }
            
            if (right_select) {
                // Set up the tree: set_op_node has left (current select) and right as children
                select_node->parent = set_op_node;
                right_select->parent = set_op_node;
                set_op_node->first_child = select_node;
                select_node->next_sibling = right_select;
                set_op_node->child_count = 2;
                
                return set_op_node;
            }
        }
    }
    
    // Consume any trailing semicolon
    if (current_token_ && current_token_->type == tokenizer::TokenType::Delimiter &&
        current_token_->value == ";") {
        advance();
    }
    
    return select_node;
}

ast::ASTNode* Parser::parse_insert_stmt() {
    // Consume INSERT keyword
    advance();
    
    // Create INSERT statement node
    auto* insert_node = arena_.allocate<ast::ASTNode>();
    new (insert_node) ast::ASTNode(ast::NodeType::InsertStmt);
    insert_node->node_id = next_node_id_++;
    
    // Consume remaining tokens (minimal implementation)
    while (current_token_ && 
           current_token_->type != tokenizer::TokenType::EndOfFile &&
           !(current_token_->type == tokenizer::TokenType::Delimiter && 
             current_token_->value == ";")) {
        advance();
    }
    
    return insert_node;
}

ast::ASTNode* Parser::parse_update_stmt() {
    // Consume UPDATE keyword
    advance();
    
    // Create UPDATE statement node
    auto* update_node = arena_.allocate<ast::ASTNode>();
    new (update_node) ast::ASTNode(ast::NodeType::UpdateStmt);
    update_node->node_id = next_node_id_++;
    
    // Consume remaining tokens (minimal implementation)
    while (current_token_ && 
           current_token_->type != tokenizer::TokenType::EndOfFile &&
           !(current_token_->type == tokenizer::TokenType::Delimiter && 
             current_token_->value == ";")) {
        advance();
    }
    
    return update_node;
}

ast::ASTNode* Parser::parse_delete_stmt() {
    // Consume DELETE keyword
    advance();
    
    // Create DELETE statement node
    auto* delete_node = arena_.allocate<ast::ASTNode>();
    new (delete_node) ast::ASTNode(ast::NodeType::DeleteStmt);
    delete_node->node_id = next_node_id_++;
    
    // Consume remaining tokens (minimal implementation)
    while (current_token_ && 
           current_token_->type != tokenizer::TokenType::EndOfFile &&
           !(current_token_->type == tokenizer::TokenType::Delimiter && 
             current_token_->value == ";")) {
        advance();
    }
    
    return delete_node;
}

ast::ASTNode* Parser::parse_create_stmt() {
    // Consume CREATE keyword
    advance();
    
    if (!current_token_ || current_token_->type != tokenizer::TokenType::Keyword) {
        return nullptr;
    }
    
    std::string_view create_type = current_token_->value;
    
    // Dispatch based on CREATE type
    if (create_type == "TABLE" || create_type == "table" ||
        create_type == "TEMPORARY" || create_type == "temporary" ||
        create_type == "TEMP" || create_type == "temp") {
        // Handle CREATE [TEMP|TEMPORARY] TABLE
        if (create_type == "TEMPORARY" || create_type == "temporary" ||
            create_type == "TEMP" || create_type == "temp") {
            advance();  // Skip TEMP/TEMPORARY
            if (!current_token_ || (current_token_->value != "TABLE" && current_token_->value != "table")) {
                return nullptr;
            }
        }
        // Now we're at TABLE
        return parse_create_table_impl();
    } else if (create_type == "INDEX" || create_type == "index" ||
               create_type == "UNIQUE" || create_type == "unique") {
        // Handle CREATE [UNIQUE] INDEX
        return parse_create_index_impl();
    } else if (create_type == "VIEW" || create_type == "view" ||
               create_type == "OR" || create_type == "or") {
        // Handle CREATE [OR REPLACE] VIEW
        if (create_type == "OR" || create_type == "or") {
            advance();  // Skip OR
            if (!current_token_ || (current_token_->value != "REPLACE" && current_token_->value != "replace")) {
                return nullptr;
            }
            advance();  // Skip REPLACE
            if (!current_token_ || (current_token_->value != "VIEW" && current_token_->value != "view")) {
                return nullptr;
            }
        }
        return parse_create_view_impl();
    }
    
    return nullptr;
}

ast::ASTNode* Parser::parse_create_table_stmt() {
    // This is the old entry point, redirect to new implementation
    advance();  // Skip CREATE
    return parse_create_table_impl();
}

ast::ASTNode* Parser::parse_create_table_impl() {
    // We're at TABLE keyword
    advance();  // Skip TABLE
    
    // Create CREATE TABLE statement node
    auto* create_node = arena_.allocate<ast::ASTNode>();
    new (create_node) ast::ASTNode(ast::NodeType::CreateTableStmt);
    create_node->node_id = next_node_id_++;
    
    // Check for IF NOT EXISTS
    if (current_token_ && (current_token_->value == "IF" || current_token_->value == "if")) {
        advance();
        if (current_token_ && (current_token_->value == "NOT" || current_token_->value == "not")) {
            advance();
            if (current_token_ && (current_token_->value == "EXISTS" || current_token_->value == "exists")) {
                advance();
                create_node->semantic_flags |= 0x01;  // IF NOT EXISTS flag
            }
        }
    }
    
    // Get table name
    if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier) {
        create_node->primary_text = current_token_->value;
        advance();
    }
    
    // Consume remaining tokens (columns, constraints, etc.)
    // This is a simplified implementation - full parsing would handle column definitions
    int paren_depth = 0;
    while (current_token_ && 
           current_token_->type != tokenizer::TokenType::EndOfFile &&
           !(current_token_->type == tokenizer::TokenType::Delimiter && 
             current_token_->value == ";" && paren_depth == 0)) {
        if (current_token_->value == "(") paren_depth++;
        else if (current_token_->value == ")") paren_depth--;
        advance();
    }
    
    return create_node;
}

ast::ASTNode* Parser::parse_create_index_stmt() {
    // Entry point for standalone parse_create_index_stmt calls
    advance();  // Skip CREATE
    return parse_create_index_impl();
}

ast::ASTNode* Parser::parse_create_index_impl() {
    // We're already past CREATE, now at either UNIQUE or INDEX
    bool is_unique = false;
    if (current_token_ && (current_token_->value == "UNIQUE" || current_token_->value == "unique")) {
        is_unique = true;
        advance();
        // Now we should be at INDEX
        if (!current_token_ || (current_token_->value != "INDEX" && current_token_->value != "index")) {
            return nullptr;
        }
    } else if (!current_token_ || (current_token_->value != "INDEX" && current_token_->value != "index")) {
        // If not UNIQUE, must be INDEX
        return nullptr;
    }
    advance();  // Skip INDEX
    
    // Create CREATE INDEX statement node
    auto* create_node = arena_.allocate<ast::ASTNode>();
    new (create_node) ast::ASTNode(ast::NodeType::CreateIndexStmt);
    create_node->node_id = next_node_id_++;
    if (is_unique) {
        create_node->semantic_flags |= 0x02;  // UNIQUE flag
    }
    
    // Check for IF NOT EXISTS
    if (current_token_ && (current_token_->value == "IF" || current_token_->value == "if")) {
        advance();
        if (current_token_ && (current_token_->value == "NOT" || current_token_->value == "not")) {
            advance();
            if (current_token_ && (current_token_->value == "EXISTS" || current_token_->value == "exists")) {
                advance();
                create_node->semantic_flags |= 0x01;  // IF NOT EXISTS flag
            }
        }
    }
    
    // Get index name
    if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier) {
        create_node->primary_text = current_token_->value;
        advance();
    }
    
    // Expect ON keyword
    if (current_token_ && (current_token_->value == "ON" || current_token_->value == "on")) {
        advance();
        
        // Get table name
        if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier) {
            create_node->schema_name = current_token_->value;  // Use schema_name for table name
            advance();
        }
    }
    
    // Consume remaining tokens (column list, WHERE clause, etc.)
    int paren_depth = 0;
    while (current_token_ && 
           current_token_->type != tokenizer::TokenType::EndOfFile &&
           !(current_token_->type == tokenizer::TokenType::Delimiter && 
             current_token_->value == ";" && paren_depth == 0)) {
        if (current_token_->value == "(") paren_depth++;
        else if (current_token_->value == ")") paren_depth--;
        advance();
    }
    
    return create_node;
}

ast::ASTNode* Parser::parse_create_view_stmt() {
    // Entry point for standalone parse_create_view_stmt calls
    advance();  // Skip CREATE
    return parse_create_view_impl();
}

ast::ASTNode* Parser::parse_create_view_impl() {
    // We might be at VIEW or need to skip OR REPLACE
    // This was already handled in parse_create_stmt
    
    // Expect VIEW keyword
    if (!current_token_ || (current_token_->value != "VIEW" && current_token_->value != "view")) {
        return nullptr;
    }
    advance();  // Skip VIEW
    
    // Create CREATE VIEW statement node
    auto* create_node = arena_.allocate<ast::ASTNode>();
    new (create_node) ast::ASTNode(ast::NodeType::CreateViewStmt);
    create_node->node_id = next_node_id_++;
    
    // Get view name
    if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier) {
        create_node->primary_text = current_token_->value;
        advance();
    }
    
    // Optional column list
    if (current_token_ && current_token_->value == "(") {
        // Skip column list for now
        int paren_depth = 1;
        advance();
        while (current_token_ && paren_depth > 0) {
            if (current_token_->value == "(") paren_depth++;
            else if (current_token_->value == ")") paren_depth--;
            advance();
        }
    }
    
    // Expect AS keyword
    if (current_token_ && current_token_->keyword_id == db25::Keyword::AS) {
        advance();
        
        // Parse the SELECT statement
        ast::ASTNode* select_stmt = parse_select_stmt();
        if (select_stmt) {
            select_stmt->parent = create_node;
            create_node->first_child = select_stmt;
            create_node->child_count = 1;
        }
    }
    
    return create_node;
}

ast::ASTNode* Parser::parse_drop_stmt() {
    // Consume DROP keyword
    advance();
    
    // Create DROP statement node
    auto* drop_node = arena_.allocate<ast::ASTNode>();
    new (drop_node) ast::ASTNode(ast::NodeType::DropStmt);
    drop_node->node_id = next_node_id_++;
    
    // Get object type (TABLE, INDEX, VIEW, etc.)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
        std::string_view obj_type = current_token_->value;
        
        if (obj_type == "TABLE" || obj_type == "table") {
            drop_node->semantic_flags |= 0x10;  // DROP TABLE
        } else if (obj_type == "INDEX" || obj_type == "index") {
            drop_node->semantic_flags |= 0x20;  // DROP INDEX
        } else if (obj_type == "VIEW" || obj_type == "view") {
            drop_node->semantic_flags |= 0x30;  // DROP VIEW
        }
        advance();
    }
    
    // Check for IF EXISTS
    if (current_token_ && (current_token_->value == "IF" || current_token_->value == "if")) {
        advance();
        if (current_token_ && (current_token_->value == "EXISTS" || current_token_->value == "exists")) {
            advance();
            drop_node->semantic_flags |= 0x01;  // IF EXISTS flag
        }
    }
    
    // Get object name
    if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier) {
        drop_node->primary_text = current_token_->value;
        advance();
    }
    
    // Handle CASCADE/RESTRICT
    if (current_token_ && (current_token_->value == "CASCADE" || current_token_->value == "cascade")) {
        drop_node->semantic_flags |= 0x04;  // CASCADE flag
        advance();
    } else if (current_token_ && (current_token_->value == "RESTRICT" || current_token_->value == "restrict")) {
        drop_node->semantic_flags |= 0x08;  // RESTRICT flag
        advance();
    }
    
    return drop_node;
}

ast::ASTNode* Parser::parse_alter_table_stmt() {
    // Consume ALTER keyword
    advance();
    
    // Expect TABLE keyword
    if (!current_token_ || (current_token_->value != "TABLE" && current_token_->value != "table")) {
        return nullptr;
    }
    advance();
    
    // Create ALTER TABLE statement node
    auto* alter_node = arena_.allocate<ast::ASTNode>();
    new (alter_node) ast::ASTNode(ast::NodeType::AlterTableStmt);
    alter_node->node_id = next_node_id_++;
    
    // Get table name
    if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier) {
        alter_node->primary_text = current_token_->value;
        advance();
    }
    
    // Parse alter action (ADD, DROP, RENAME, etc.)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
        std::string_view action = current_token_->value;
        
        if (action == "ADD" || action == "add") {
            alter_node->semantic_flags |= 0x10;  // ADD action
            advance();
            
            // Could be ADD COLUMN, ADD CONSTRAINT, etc.
            if (current_token_ && (current_token_->value == "COLUMN" || current_token_->value == "column")) {
                advance();  // Skip optional COLUMN keyword
            }
        } else if (action == "DROP" || action == "drop") {
            alter_node->semantic_flags |= 0x20;  // DROP action
            advance();
            
            // Could be DROP COLUMN, DROP CONSTRAINT, etc.
            if (current_token_ && (current_token_->value == "COLUMN" || current_token_->value == "column")) {
                advance();  // Skip optional COLUMN keyword
            }
        } else if (action == "RENAME" || action == "rename") {
            alter_node->semantic_flags |= 0x30;  // RENAME action
            advance();
            
            // Could be RENAME TO, RENAME COLUMN
            if (current_token_ && (current_token_->value == "TO" || current_token_->value == "to")) {
                advance();
            } else if (current_token_ && (current_token_->value == "COLUMN" || current_token_->value == "column")) {
                advance();
            }
        } else if (action == "ALTER" || action == "alter") {
            alter_node->semantic_flags |= 0x40;  // ALTER COLUMN action
            advance();
            
            if (current_token_ && (current_token_->value == "COLUMN" || current_token_->value == "column")) {
                advance();
            }
        }
    }
    
    // Consume remaining tokens
    while (current_token_ && 
           current_token_->type != tokenizer::TokenType::EndOfFile &&
           !(current_token_->type == tokenizer::TokenType::Delimiter && 
             current_token_->value == ";")) {
        advance();
    }
    
    return alter_node;
}

ast::ASTNode* Parser::parse_truncate_stmt() {
    // Consume TRUNCATE keyword
    advance();
    
    // Expect TABLE keyword (optional in some dialects)
    if (current_token_ && (current_token_->value == "TABLE" || current_token_->value == "table")) {
        advance();
    }
    
    // Create TRUNCATE statement node
    auto* truncate_node = arena_.allocate<ast::ASTNode>();
    new (truncate_node) ast::ASTNode(ast::NodeType::TruncateStmt);
    truncate_node->node_id = next_node_id_++;
    
    // Get table name
    if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier) {
        truncate_node->primary_text = current_token_->value;
        advance();
    }
    
    // Handle CASCADE/RESTRICT (PostgreSQL)
    if (current_token_ && (current_token_->value == "CASCADE" || current_token_->value == "cascade")) {
        truncate_node->semantic_flags |= 0x04;  // CASCADE flag
        advance();
    } else if (current_token_ && (current_token_->value == "RESTRICT" || current_token_->value == "restrict")) {
        truncate_node->semantic_flags |= 0x08;  // RESTRICT flag
        advance();
    }
    
    return truncate_node;
}

// ========== SELECT Clause Parsers ==========

ast::ASTNode* Parser::parse_select_list() {
    // First check if we immediately hit FROM or another clause keyword
    // This handles "SELECT FROM ..." which should be invalid
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
        const auto& kw = current_token_->value;
        if (kw == "FROM" || kw == "from" ||
            kw == "WHERE" || kw == "where" ||
            kw == "GROUP" || kw == "group" ||
            kw == "HAVING" || kw == "having" ||
            kw == "ORDER" || kw == "order" ||
            kw == "LIMIT" || kw == "limit" ||
            kw == "UNION" || kw == "union" ||
            kw == "INTERSECT" || kw == "intersect" ||
            kw == "EXCEPT" || kw == "except") {
            // Empty SELECT list - return nullptr to indicate error
            return nullptr;
        }
    }
    
    // First, check if we can parse at least one item
    ast::ASTNode* first_item = nullptr;
    
    // Check for * (star)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Operator &&
        current_token_->value == "*") {
        first_item = arena_.allocate<ast::ASTNode>();
        new (first_item) ast::ASTNode(ast::NodeType::Star);
        first_item->node_id = next_node_id_++;
        advance();
    }
    // Parse any other select item (column, expression, function)
    else if (current_token_) {
        first_item = parse_select_item();
    }
    
    // If we couldn't parse any item, return nullptr
    if (!first_item) {
        return nullptr;
    }
    
    // Now create the SELECT list node since we have at least one item
    auto* list_node = arena_.allocate<ast::ASTNode>();
    new (list_node) ast::ASTNode(ast::NodeType::SelectList);
    list_node->node_id = next_node_id_++;
    
    // Add the first item
    first_item->parent = list_node;
    list_node->first_child = first_item;
    list_node->child_count = 1;
    
    ast::ASTNode* last_item = first_item;
    
    // Parse remaining items
    while (current_token_ && current_token_->type == tokenizer::TokenType::Delimiter &&
           current_token_->value == ",") {
        advance(); // consume comma
        
        ast::ASTNode* item = nullptr;
        
        // Check for * (star)
        if (current_token_ && current_token_->type == tokenizer::TokenType::Operator &&
            current_token_->value == "*") {
            item = arena_.allocate<ast::ASTNode>();
            new (item) ast::ASTNode(ast::NodeType::Star);
            item->node_id = next_node_id_++;
            advance();
        }
        // Parse any other select item (column, expression, function)
        else if (current_token_) {
            item = parse_select_item();
        }
        
        if (item) {
            item->parent = list_node;
            last_item->next_sibling = item;
            last_item = item;
            list_node->child_count++;
        }
    }
    
    return list_node;
}

ast::ASTNode* Parser::parse_from_clause() {
    // Parse first table reference
    auto* table_ref = parse_table_reference();
    if (!table_ref) {
        // No table reference means no FROM clause
        return nullptr;
    }
    
    // Now create FROM clause node since we have at least one table
    auto* from_node = arena_.allocate<ast::ASTNode>();
    new (from_node) ast::ASTNode(ast::NodeType::FromClause);
    from_node->node_id = next_node_id_++;
    
    table_ref->parent = from_node;
    from_node->first_child = table_ref;
    from_node->child_count = 1;
    ast::ASTNode* last_child = table_ref;
    
    // Check for comma-separated tables or JOINs
    while (current_token_) {
        // Handle comma-separated tables (old-style join)
        if (current_token_->type == tokenizer::TokenType::Delimiter &&
            current_token_->value == ",") {
            advance(); // consume comma

            if (auto* next_table = parse_table_reference()) {
                next_table->parent = from_node;
                // last_child is always valid (initialized to table_ref)
                last_child->next_sibling = next_table;
                last_child = next_table;
                from_node->child_count++;
            }
        }
        // Handle JOIN keywords
        else if (current_token_->type == tokenizer::TokenType::Keyword) {
            const auto& kw = current_token_->value;
            
            // Check for various JOIN types
            bool is_join = (kw == "JOIN" || kw == "join" ||
                           kw == "LEFT" || kw == "left" ||
                           kw == "RIGHT" || kw == "right" ||
                           kw == "INNER" || kw == "inner" ||
                           kw == "FULL" || kw == "full" ||
                           kw == "CROSS" || kw == "cross");
            
            if (is_join) {
                auto* join_clause = parse_join_clause();
                // parse_join_clause always returns a valid node
                join_clause->parent = from_node;
                // last_child is always valid (initialized to table_ref)
                last_child->next_sibling = join_clause;
                last_child = join_clause;
                from_node->child_count++;
            } else {
                // Not a JOIN keyword, stop parsing FROM clause
                break;
            }
        }
        else {
            // No more tables or joins
            break;
        }
    }
    
    return from_node;
}

ast::ASTNode* Parser::parse_join_clause() {
    // Create JOIN clause node
    auto* join_node = arena_.allocate<ast::ASTNode>();
    new (join_node) ast::ASTNode(ast::NodeType::JoinClause);
    join_node->node_id = next_node_id_++;
    
    // Store JOIN type (LEFT, RIGHT, INNER, etc.)
    std::string join_type;
    
    // Handle JOIN type prefixes (LEFT, RIGHT, INNER, FULL, CROSS)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
        const auto& kw = current_token_->value;
        if (kw == "LEFT" || kw == "left" ||
            kw == "RIGHT" || kw == "right" ||
            kw == "INNER" || kw == "inner" ||
            kw == "FULL" || kw == "full" ||
            kw == "CROSS" || kw == "cross") {
            join_type = kw;
            advance(); // consume JOIN type
            
            // Also handle OUTER keyword (LEFT OUTER JOIN)
            if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                (current_token_->value == "OUTER" || current_token_->value == "outer")) {
                join_type += " OUTER";
                advance();
            }
        }
    }
    
    // Consume JOIN keyword
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "JOIN" || current_token_->value == "join")) {
        if (!join_type.empty()) {
            join_type += " ";
        }
        join_type += "JOIN";
        advance();
    }
    
    // Store join type in the node
    if (!join_type.empty()) {
        join_node->primary_text = copy_to_arena(join_type);
    }
    
    // Parse the joined table
    auto* table = parse_table_reference();
    if (table) {
        table->parent = join_node;
        join_node->first_child = table;
        join_node->child_count++;
        
        // Parse ON condition if present
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
            (current_token_->value == "ON" || current_token_->value == "on")) {
            advance(); // consume ON
            
            // Parse the join condition as an expression
            auto* condition = parse_expression(0);
            if (condition) {
                condition->parent = join_node;
                table->next_sibling = condition;
                join_node->child_count++;
            }
        }
        // Could also have USING clause (not implemented yet)
        else if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                 (current_token_->value == "USING" || current_token_->value == "using")) {
            // TODO: Parse USING clause
            // For now, just consume tokens until we hit another keyword
            advance(); // consume USING
            if (current_token_ && current_token_->value == "(") {
                advance();
                while (current_token_ && current_token_->value != ")") {
                    advance();
                }
                if (current_token_ && current_token_->value == ")") {
                    if (parenthesis_depth_ > 0) parenthesis_depth_--;
                    advance();
                }
            }
        }
    }
    
    return join_node;
}

ast::ASTNode* Parser::parse_where_clause() {
    // Parse condition expression
    auto* condition = parse_expression(0);
    if (!condition) {
        // No condition means no WHERE clause
        return nullptr;
    }
    
    // Create WHERE clause node since we have a condition
    auto* where_node = arena_.allocate<ast::ASTNode>();
    new (where_node) ast::ASTNode(ast::NodeType::WhereClause);
    where_node->node_id = next_node_id_++;
    
    condition->parent = where_node;
    where_node->first_child = condition;
    where_node->child_count = 1;
    
    return where_node;
}

ast::ASTNode* Parser::parse_group_by_clause() {
    // Parse first GROUP BY item
    ast::ASTNode* first_item = nullptr;
    
    // Could be a number (GROUP BY 1, 2), expression, or column
    if (current_token_ && current_token_->type == tokenizer::TokenType::Number) {
        // GROUP BY position
        first_item = arena_.allocate<ast::ASTNode>();
        new (first_item) ast::ASTNode(ast::NodeType::IntegerLiteral);
        first_item->node_id = next_node_id_++;
        first_item->primary_text = copy_to_arena(current_token_->value);
        advance();
    } else {
        // Parse as expression (handles columns, function calls, etc.)
        first_item = parse_expression(0);
    }
    
    // If we couldn't parse any item, return nullptr
    if (!first_item) {
        return nullptr;
    }
    
    // Now create GROUP BY clause node since we have at least one item
    auto* group_node = arena_.allocate<ast::ASTNode>();
    new (group_node) ast::ASTNode(ast::NodeType::GroupByClause);
    group_node->node_id = next_node_id_++;
    
    // Add first item
    first_item->parent = group_node;
    group_node->first_child = first_item;
    group_node->child_count = 1;
    ast::ASTNode* last_item = first_item;
    
    // Parse additional comma-separated GROUP BY items
    while (current_token_ && current_token_->type == tokenizer::TokenType::Delimiter &&
           current_token_->value == ",") {
        advance(); // consume comma
        
        ast::ASTNode* group_item = nullptr;
        
        // Could be a number (GROUP BY 1, 2), expression, or column
        if (current_token_ && current_token_->type == tokenizer::TokenType::Number) {
            // GROUP BY position
            group_item = arena_.allocate<ast::ASTNode>();
            new (group_item) ast::ASTNode(ast::NodeType::IntegerLiteral);
            group_item->node_id = next_node_id_++;
            group_item->primary_text = copy_to_arena(current_token_->value);
            advance();
        } else {
            // Parse as expression (handles columns, function calls, etc.)
            group_item = parse_expression(0);
        }
        
        // Add item to GROUP BY clause
        if (group_item) {
            group_item->parent = group_node;
            last_item->next_sibling = group_item;
            last_item = group_item;
            group_node->child_count++;
        } else {
            // If we couldn't parse an item after comma, stop
            break;
        }
    }
    
    return group_node;
}

ast::ASTNode* Parser::parse_having_clause() {
    // Parse condition expression (same as WHERE but can contain aggregates)
    auto* condition = parse_expression(0);
    if (!condition) {
        // No condition means no HAVING clause
        return nullptr;
    }
    
    // Create HAVING clause node since we have a condition
    auto* having_node = arena_.allocate<ast::ASTNode>();
    new (having_node) ast::ASTNode(ast::NodeType::HavingClause);
    having_node->node_id = next_node_id_++;
    
    condition->parent = having_node;
    having_node->first_child = condition;
    having_node->child_count = 1;
    
    return having_node;
}

ast::ASTNode* Parser::parse_order_by_clause() {
    // Parse first ORDER BY item
    ast::ASTNode* first_item = parse_expression(0);
    
    if (!first_item) {
        // If we can't parse any expression, return nullptr
        return nullptr;
    }
    
    // Parse ASC/DESC direction for first item (default is ASC)
    // We'll store the direction in the order_item's semantic_flags
    // Using bit 7 for DESC (0 = ASC, 1 = DESC)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
        if (current_token_->value == "DESC" || current_token_->value == "desc") {
            first_item->semantic_flags |= (1 << 7); // Set bit 7 for DESC
            advance();
        } else if (current_token_->value == "ASC" || current_token_->value == "asc") {
            // ASC is default, bit 7 remains 0
            advance();
        }
    }
    
    // Parse NULLS FIRST/LAST
    // Using bit 5 for NULLS ordering (0 = default, 1 = explicit)
    // Using bit 4 for FIRST/LAST (0 = LAST, 1 = FIRST)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "NULLS" || current_token_->value == "nulls")) {
        advance(); // consume NULLS
        
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
            if (current_token_->value == "FIRST" || current_token_->value == "first") {
                first_item->semantic_flags |= (1 << 5); // Mark NULLS ordering as explicit
                first_item->semantic_flags |= (1 << 4); // Set FIRST
                advance();
            } else if (current_token_->value == "LAST" || current_token_->value == "last") {
                first_item->semantic_flags |= (1 << 5); // Mark NULLS ordering as explicit
                // bit 4 remains 0 for LAST
                advance();
            }
        }
    }
    
    // Now create ORDER BY clause node since we have at least one item
    auto* order_node = arena_.allocate<ast::ASTNode>();
    new (order_node) ast::ASTNode(ast::NodeType::OrderByClause);
    order_node->node_id = next_node_id_++;
    
    // Add first item
    first_item->parent = order_node;
    order_node->first_child = first_item;
    order_node->child_count = 1;
    ast::ASTNode* last_item = first_item;
    
    // Parse additional comma-separated ORDER BY items
    while (current_token_ && current_token_->type == tokenizer::TokenType::Delimiter &&
           current_token_->value == ",") {
        advance(); // consume comma
        
        // Parse expression
        ast::ASTNode* order_item = parse_expression(0);
        
        if (!order_item) {
            // If we can't parse an expression after comma, stop
            break;
        }
        
        // Parse ASC/DESC direction
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
            if (current_token_->value == "DESC" || current_token_->value == "desc") {
                order_item->semantic_flags |= (1 << 7); // Set bit 7 for DESC
                advance();
            } else if (current_token_->value == "ASC" || current_token_->value == "asc") {
                // ASC is default, bit 7 remains 0
                advance();
            }
        }
        
        // Parse NULLS FIRST/LAST
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
            (current_token_->value == "NULLS" || current_token_->value == "nulls")) {
            advance(); // consume NULLS
            
            if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
                if (current_token_->value == "FIRST" || current_token_->value == "first") {
                    order_item->semantic_flags |= (1 << 5); // Mark NULLS ordering as explicit
                    order_item->semantic_flags |= (1 << 4); // Set FIRST
                    advance();
                } else if (current_token_->value == "LAST" || current_token_->value == "last") {
                    order_item->semantic_flags |= (1 << 5); // Mark NULLS ordering as explicit
                    // bit 4 remains 0 for LAST
                    advance();
                }
            }
        }
        
        // Add item to ORDER BY clause
        order_item->parent = order_node;
        last_item->next_sibling = order_item;
        last_item = order_item;
        order_node->child_count++;
    }
    
    return order_node;
}

ast::ASTNode* Parser::parse_limit_clause() {
    // Parse limit number
    if (!current_token_ || current_token_->type != tokenizer::TokenType::Number) {
        // No number after LIMIT
        return nullptr;
    }
    
    // Create LIMIT clause node since we have a number
    auto* limit_node = arena_.allocate<ast::ASTNode>();
    new (limit_node) ast::ASTNode(ast::NodeType::LimitClause);
    limit_node->node_id = next_node_id_++;
    
    // Create and add the limit number node
    auto* num_node = arena_.allocate<ast::ASTNode>();
    new (num_node) ast::ASTNode(ast::NodeType::IntegerLiteral);
    num_node->node_id = next_node_id_++;
    
    // Store the limit value
    num_node->primary_text = copy_to_arena(current_token_->value);
    
    num_node->parent = limit_node;
    limit_node->first_child = num_node;
    limit_node->child_count = 1;
    
    advance();
    
    // Check for OFFSET
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "OFFSET" || current_token_->value == "offset")) {
        advance();
        
        if (current_token_ && current_token_->type == tokenizer::TokenType::Number) {
            auto* offset_node = arena_.allocate<ast::ASTNode>();
            new (offset_node) ast::ASTNode(ast::NodeType::IntegerLiteral);
            offset_node->node_id = next_node_id_++;
            
            // Store the offset value
            offset_node->primary_text = copy_to_arena(current_token_->value);
            
            offset_node->parent = limit_node;
            num_node->next_sibling = offset_node;
            limit_node->child_count++;
            
            advance();
        }
    }
    
    return limit_node;
}

ast::ASTNode* Parser::parse_identifier() {
    // Accept both identifiers and keywords as identifiers in expression context
    if (!current_token_ || 
        (current_token_->type != tokenizer::TokenType::Identifier &&
         current_token_->type != tokenizer::TokenType::Keyword)) {
        return nullptr;
    }
    
    auto* id_node = arena_.allocate<ast::ASTNode>();
    new (id_node) ast::ASTNode(ast::NodeType::Identifier);
    id_node->node_id = next_node_id_++;
    
    // Store identifier text
    id_node->primary_text = copy_to_arena(current_token_->value);
    
    advance();
    return id_node;
}

ast::ASTNode* Parser::parse_table_reference() {
    if (!current_token_) {
        return nullptr;
    }
    
    // Check for subquery (parenthesized SELECT)
    if (current_token_->type == tokenizer::TokenType::Delimiter &&
        current_token_->value == "(") {
        // Peek ahead to see if it's a SELECT
        parenthesis_depth_++;
        advance(); // consume '('
        
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
            (current_token_->value == "SELECT" || current_token_->value == "select")) {
            // It's a subquery
            auto* subquery_node = arena_.allocate<ast::ASTNode>();
            new (subquery_node) ast::ASTNode(ast::NodeType::Subquery);
            subquery_node->node_id = next_node_id_++;
            
            // Parse the SELECT statement
            auto* select_stmt = parse_select_stmt();
            if (select_stmt) {
                select_stmt->parent = subquery_node;
                subquery_node->first_child = select_stmt;
                subquery_node->child_count = 1;
            }
            
            // Consume closing ')'
            if (current_token_ && current_token_->value == ")") {
                if (parenthesis_depth_ > 0) parenthesis_depth_--;
                advance();
            }
            
            // Check for alias (AS keyword is optional)
            if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                current_token_->keyword_id == db25::Keyword::AS) {
                advance();
            }
            
            // Get alias identifier (required for subqueries in FROM)
            if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier) {
                subquery_node->schema_name = copy_to_arena(current_token_->value);
                subquery_node->semantic_flags |= static_cast<uint16_t>(ast::NodeFlags::HasAlias);
                advance();
            }
            
            return subquery_node;
        } else {
            // Not a subquery, might be an error
            return nullptr;
        }
    }
    
    // Parse simple table name
    if (current_token_->type == tokenizer::TokenType::Identifier) {
        auto* table_node = arena_.allocate<ast::ASTNode>();
        new (table_node) ast::ASTNode(ast::NodeType::TableRef);
        table_node->node_id = next_node_id_++;
        
        // Store table name
        table_node->primary_text = copy_to_arena(current_token_->value);
        
        advance();
        
        // Check for alias (AS keyword is optional)
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
            current_token_->keyword_id == db25::Keyword::AS) {
            advance();
        }
        
        // Check for alias identifier
        if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier &&
            // Make sure it's not a keyword that could follow
            current_token_->value != "WHERE" && current_token_->value != "where" &&
            current_token_->value != "JOIN" && current_token_->value != "join" &&
            current_token_->value != "LEFT" && current_token_->value != "left" &&
            current_token_->value != "RIGHT" && current_token_->value != "right" &&
            current_token_->value != "INNER" && current_token_->value != "inner" &&
            current_token_->value != "FULL" && current_token_->value != "full" &&
            current_token_->value != "CROSS" && current_token_->value != "cross" &&
            current_token_->value != "ON" && current_token_->value != "on" &&
            current_token_->value != "GROUP" && current_token_->value != "group" &&
            current_token_->value != "ORDER" && current_token_->value != "order") {
            // Store alias in schema_name field (repurposed for alias)
            table_node->schema_name = copy_to_arena(current_token_->value);
            table_node->semantic_flags |= static_cast<uint16_t>(ast::NodeFlags::HasAlias);
            advance();
        }
        
        return table_node;
    }
    
    return nullptr;
}

// ========== Column Reference Parser ==========

ast::ASTNode* Parser::parse_column_ref() {
    // Parse column references: "id", "users.id", "schema.table.column"
    // Accepts both identifiers and keywords as column names
    
    if (!current_token_ || 
        (current_token_->type != tokenizer::TokenType::Identifier &&
         current_token_->type != tokenizer::TokenType::Keyword)) {
        return nullptr;
    }
    
    // Collect all parts of the qualified name
    std::vector<std::string_view> parts;
    parts.push_back(current_token_->value);
    advance();
    
    // Check for qualified name parts
    // Note: The tokenizer might classify "." as Operator, not Delimiter
    while (current_token_ && 
           (current_token_->type == tokenizer::TokenType::Delimiter ||
            current_token_->type == tokenizer::TokenType::Operator) &&
           current_token_->value == ".") {
        advance(); // consume dot
        
        if (current_token_ && 
            (current_token_->type == tokenizer::TokenType::Identifier ||
             current_token_->type == tokenizer::TokenType::Keyword)) {
            // Allow keywords as column names in qualified references (e.g., h.level)
            parts.push_back(current_token_->value);
            advance();
        } else {
            break; // Invalid qualified name
        }
    }
    
    // Create appropriate node based on qualification
    auto* col_ref = arena_.allocate<ast::ASTNode>();
    new (col_ref) ast::ASTNode(ast::NodeType::ColumnRef);
    col_ref->node_id = next_node_id_++;
    
    // Build full qualified name
    std::string qualified_name;
    for (size_t i = 0; i < parts.size(); i++) {
        if (i > 0) {
            qualified_name += '.';
        }
        qualified_name += parts[i];
    }
    
    col_ref->primary_text = copy_to_arena(qualified_name);
    return col_ref;
}

// ========== Function Call Parser ==========

ast::ASTNode* Parser::parse_function_call() {
    // Parse function calls: "COUNT(*)", "MAX(id)", "SUM(price * quantity)"
    // Accept both identifiers and keywords as function names
    
    if (!current_token_ || 
        (current_token_->type != tokenizer::TokenType::Identifier &&
         current_token_->type != tokenizer::TokenType::Keyword)) {
        return nullptr;
    }
    
    // Store function name
    std::string_view func_name = current_token_->value;
    advance();
    
    // Must be followed by '('
    if (!current_token_ || current_token_->type != tokenizer::TokenType::Delimiter ||
        current_token_->value != "(") {
        // Not a function call, backtrack would be needed
        // For now, return nullptr
        return nullptr;
    }
    
    // Create FunctionCall node
    auto* func_call = arena_.allocate<ast::ASTNode>();
    new (func_call) ast::ASTNode(ast::NodeType::FunctionCall);
    func_call->node_id = next_node_id_++;
    
    // Store function name
    func_call->primary_text = copy_to_arena(func_name);
    
    parenthesis_depth_++;
    advance(); // consume '('
    
    // Check for DISTINCT keyword (for aggregate functions)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "DISTINCT" || current_token_->value == "distinct")) {
        func_call->flags = func_call->flags | ast::NodeFlags::Distinct;
        advance(); // consume DISTINCT
    }
    
    // Parse arguments
    ast::ASTNode* last_arg = nullptr;
    
    // Check for empty argument list
    if (current_token_ && current_token_->type == tokenizer::TokenType::Delimiter &&
        current_token_->value == ")") {
        // Empty argument list
        if (parenthesis_depth_ > 0) parenthesis_depth_--;
            advance(); // consume ')'
    } else {
        // Parse comma-separated arguments
        while (current_token_ && !(current_token_->type == tokenizer::TokenType::Delimiter &&
                                  current_token_->value == ")")) {
            ast::ASTNode* arg = nullptr;
            
            // Special case for COUNT(*)
            if (current_token_->type == tokenizer::TokenType::Operator &&
                current_token_->value == "*") {
                arg = arena_.allocate<ast::ASTNode>();
                new (arg) ast::ASTNode(ast::NodeType::Star);
                arg->node_id = next_node_id_++;
                advance();
            } else {
                // Parse as expression
                arg = parse_expression(0);
            }
            
            if (arg) {
                arg->parent = func_call;
                if (!func_call->first_child) {
                    func_call->first_child = arg;
                } else if (last_arg) {
                    last_arg->next_sibling = arg;
                }
                last_arg = arg;
                func_call->child_count++;
            }
            
            // Check for comma
            if (current_token_ && current_token_->type == tokenizer::TokenType::Delimiter &&
                current_token_->value == ",") {
                advance(); // consume comma
            } else {
                // End of arguments (closing paren) or error
                break;
            }
        }
        
        if (current_token_ && current_token_->value == ")") {
            if (parenthesis_depth_ > 0) parenthesis_depth_--;
            advance(); // consume ')'
        }
    }
    
    // Check for OVER clause (window function)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "OVER" || current_token_->value == "over")) {
        advance(); // consume OVER
        
        // Parse window specification
        auto* window_spec = parse_window_spec();
        if (window_spec) {
            // Transform FunctionCall into WindowExpr
            // Note: We can't change node_type after construction, so we mark it as a window function
            // using semantic_flags instead
            func_call->semantic_flags |= (1 << 8);  // Bit 8 indicates window function
            
            // Add window specification as last child
            if (func_call->first_child) {
                ast::ASTNode* last = func_call->first_child;
                while (last->next_sibling) {
                    last = last->next_sibling;
                }
                last->next_sibling = window_spec;
            } else {
                func_call->first_child = window_spec;
            }
            window_spec->parent = func_call;
            func_call->child_count++;
        }
    }
    
    return func_call;
}

// ========== Window Specification Parser ==========

ast::ASTNode* Parser::parse_window_spec() {
    // Parse OVER (window_specification)
    // window_spec: ( [PARTITION BY expr, ...] [ORDER BY expr [ASC|DESC], ...] [frame_clause] )
    
    if (!current_token_ || current_token_->value != "(") {
        return nullptr;  // OVER must be followed by (
    }
    
    auto* window_spec = arena_.allocate<ast::ASTNode>();
    new (window_spec) ast::ASTNode(ast::NodeType::WindowSpec);
    window_spec->node_id = next_node_id_++;
    
    parenthesis_depth_++;
    advance(); // consume (
    
    ast::ASTNode* last_child = nullptr;
    
    // Check for empty window specification ()
    if (current_token_ && current_token_->value == ")") {
        if (parenthesis_depth_ > 0) parenthesis_depth_--;
        advance(); // consume )
        return window_spec;  // Empty window spec is valid
    }
    
    // Parse PARTITION BY clause
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "PARTITION" || current_token_->value == "partition")) {
        advance(); // consume PARTITION
        
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
            (current_token_->value == "BY" || current_token_->value == "by")) {
            advance(); // consume BY
            
            // Create PARTITION BY node
            auto* partition_node = arena_.allocate<ast::ASTNode>();
            new (partition_node) ast::ASTNode(ast::NodeType::PartitionByClause);
            partition_node->node_id = next_node_id_++;
            partition_node->parent = window_spec;
            
            // Parse partition expressions
            ast::ASTNode* last_partition_expr = nullptr;
            while (true) {
                auto* expr = parse_expression(0);
                if (!expr) break;
                
                expr->parent = partition_node;
                if (!partition_node->first_child) {
                    partition_node->first_child = expr;
                } else {
                    last_partition_expr->next_sibling = expr;
                }
                last_partition_expr = expr;
                partition_node->child_count++;
                
                // Check for comma
                if (current_token_ && current_token_->value == ",") {
                    advance(); // consume comma
                } else {
                    break;  // No more partition expressions
                }
            }
            
            // Add partition node to window spec
            if (!window_spec->first_child) {
                window_spec->first_child = partition_node;
            } else {
                last_child->next_sibling = partition_node;
            }
            last_child = partition_node;
            window_spec->child_count++;
        }
    }
    
    // Parse ORDER BY clause
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "ORDER" || current_token_->value == "order")) {
        advance(); // consume ORDER
        
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
            (current_token_->value == "BY" || current_token_->value == "by")) {
            advance(); // consume BY
            
            // Use existing ORDER BY parser
            auto* order_node = parse_order_by_clause();
            if (order_node) {
                order_node->parent = window_spec;
                
                // Add order node to window spec
                if (!window_spec->first_child) {
                    window_spec->first_child = order_node;
                } else {
                    last_child->next_sibling = order_node;
                }
                last_child = order_node;
                window_spec->child_count++;
            }
        }
    }
    
    // Parse frame clause (ROWS/RANGE BETWEEN ... AND ...)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        ((current_token_->value == "ROWS" || current_token_->value == "rows") ||
         (current_token_->value == "RANGE" || current_token_->value == "range"))) {
        
        auto* frame_node = arena_.allocate<ast::ASTNode>();
        new (frame_node) ast::ASTNode(ast::NodeType::FrameClause);
        frame_node->node_id = next_node_id_++;
        frame_node->parent = window_spec;
        
        // Store frame type (ROWS or RANGE)
        frame_node->primary_text = copy_to_arena(current_token_->value);
        advance(); // consume ROWS/RANGE
        
        // Parse BETWEEN clause
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
            (current_token_->value == "BETWEEN" || current_token_->value == "between")) {
            advance(); // consume BETWEEN
            
            // Parse frame start (UNBOUNDED PRECEDING, CURRENT ROW, N PRECEDING)
            auto* frame_start = arena_.allocate<ast::ASTNode>();
            new (frame_start) ast::ASTNode(ast::NodeType::FrameBound);
            frame_start->node_id = next_node_id_++;
            frame_start->parent = frame_node;
            
            if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                (current_token_->value == "UNBOUNDED" || current_token_->value == "unbounded")) {
                frame_start->primary_text = copy_to_arena("UNBOUNDED");
                advance(); // consume UNBOUNDED
                
                if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                    (current_token_->value == "PRECEDING" || current_token_->value == "preceding")) {
                    frame_start->schema_name = copy_to_arena("PRECEDING");
                    advance(); // consume PRECEDING
                }
            } else if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                       (current_token_->value == "CURRENT" || current_token_->value == "current")) {
                advance(); // consume CURRENT
                if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                    (current_token_->value == "ROW" || current_token_->value == "row")) {
                    frame_start->primary_text = copy_to_arena("CURRENT ROW");
                    advance(); // consume ROW
                }
            } else if (current_token_ && current_token_->type == tokenizer::TokenType::Number) {
                // N PRECEDING/FOLLOWING
                frame_start->primary_text = copy_to_arena(current_token_->value);
                advance(); // consume number
                
                if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
                    if (current_token_->value == "PRECEDING" || current_token_->value == "preceding") {
                        frame_start->schema_name = copy_to_arena("PRECEDING");
                        advance();
                    } else if (current_token_->value == "FOLLOWING" || current_token_->value == "following") {
                        frame_start->schema_name = copy_to_arena("FOLLOWING");
                        advance();
                    }
                }
            }
            
            frame_node->first_child = frame_start;
            frame_node->child_count = 1;
            
            // Parse AND
            if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                (current_token_->value == "AND" || current_token_->value == "and")) {
                advance(); // consume AND
                
                // Parse frame end
                auto* frame_end = arena_.allocate<ast::ASTNode>();
                new (frame_end) ast::ASTNode(ast::NodeType::FrameBound);
                frame_end->node_id = next_node_id_++;
                frame_end->parent = frame_node;
                
                if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                    (current_token_->value == "UNBOUNDED" || current_token_->value == "unbounded")) {
                    frame_end->primary_text = copy_to_arena("UNBOUNDED");
                    advance(); // consume UNBOUNDED
                    
                    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                        (current_token_->value == "FOLLOWING" || current_token_->value == "following")) {
                        frame_end->schema_name = copy_to_arena("FOLLOWING");
                        advance(); // consume FOLLOWING
                    }
                } else if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                           (current_token_->value == "CURRENT" || current_token_->value == "current")) {
                    advance(); // consume CURRENT
                    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                        (current_token_->value == "ROW" || current_token_->value == "row")) {
                        frame_end->primary_text = copy_to_arena("CURRENT ROW");
                        advance(); // consume ROW
                    }
                } else if (current_token_ && current_token_->type == tokenizer::TokenType::Number) {
                    // N PRECEDING/FOLLOWING
                    frame_end->primary_text = copy_to_arena(current_token_->value);
                    advance(); // consume number
                    
                    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
                        if (current_token_->value == "PRECEDING" || current_token_->value == "preceding") {
                            frame_end->schema_name = copy_to_arena("PRECEDING");
                            advance();
                        } else if (current_token_->value == "FOLLOWING" || current_token_->value == "following") {
                            frame_end->schema_name = copy_to_arena("FOLLOWING");
                            advance();
                        }
                    }
                }
                
                frame_start->next_sibling = frame_end;
                frame_node->child_count++;
            }
        }
        
        // Add frame node to window spec
        if (!window_spec->first_child) {
            window_spec->first_child = frame_node;
        } else {
            last_child->next_sibling = frame_node;
        }
        last_child = frame_node;
        window_spec->child_count++;
    }
    
    // Consume closing parenthesis
    if (current_token_ && current_token_->value == ")") {
        if (parenthesis_depth_ > 0) parenthesis_depth_--;
        advance(); // consume )
    }
    
    return window_spec;
}

// ========== SELECT Item Parser ==========

ast::ASTNode* Parser::parse_select_item() {
    // Parse a single item in SELECT list
    // Can be: *, table.*, column, expression, function call, with optional alias
    
    // First check if we've hit a clause keyword that ends the SELECT list
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword) {
        const auto& kw = current_token_->value;
        if (kw == "FROM" || kw == "from" ||
            kw == "WHERE" || kw == "where" ||
            kw == "GROUP" || kw == "group" ||
            kw == "HAVING" || kw == "having" ||
            kw == "ORDER" || kw == "order" ||
            kw == "LIMIT" || kw == "limit" ||
            kw == "UNION" || kw == "union" ||
            kw == "INTERSECT" || kw == "intersect" ||
            kw == "EXCEPT" || kw == "except") {
            // These keywords end the SELECT list
            return nullptr;
        }
    }
    
    ast::ASTNode* item = nullptr;
    
    // Check for * (star)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Operator &&
        current_token_->value == "*") {
        auto* star = arena_.allocate<ast::ASTNode>();
        new (star) ast::ASTNode(ast::NodeType::Star);
        star->node_id = next_node_id_++;
        advance();
        item = star;
    } else {
        // Otherwise, parse as expression (which handles all other cases)
        item = parse_expression(0);
    }
    
    if (!item) return nullptr;
    
    // Check for alias (AS keyword or implicit)
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        current_token_->keyword_id == db25::Keyword::AS) {
        // Consume AS keyword
        advance();
        
        // Get the alias name - allow both identifiers and keywords as aliases
        if (current_token_ && 
            (current_token_->type == tokenizer::TokenType::Identifier ||
             current_token_->type == tokenizer::TokenType::Keyword)) {
            // Store alias in the item's schema_name field (repurposed for alias)
            item->schema_name = copy_to_arena(current_token_->value);
            item->semantic_flags |= static_cast<uint16_t>(ast::NodeFlags::HasAlias);
            advance();
        }
    }
    // Check for implicit alias (identifier after expression without AS)
    else if (current_token_ && current_token_->type == tokenizer::TokenType::Identifier &&
             // Make sure it's not a keyword that could follow
             current_token_->value != "FROM" && current_token_->value != "from" &&
             current_token_->value != "WHERE" && current_token_->value != "where") {
        // Store alias
        item->schema_name = copy_to_arena(current_token_->value);
        item->semantic_flags |= static_cast<uint16_t>(ast::NodeFlags::HasAlias);
        advance();
    }
    
    return item;
}

// ========== Primary Expression Parser ==========

ast::ASTNode* Parser::parse_primary_expression() {
    DepthGuard guard(this);  // Protect against deep recursion
    if (!guard.is_valid()) return nullptr;
    
    // Parse primary expressions: literals, identifiers, column refs, function calls
    // This is called by parse_expression for the base case
    
    if (!current_token_) {
        return nullptr;
    }
    
    // Handle CASE expressions
    if (current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "CASE" || current_token_->value == "case")) {
        return parse_case_expression();
    }
    
    // Handle CAST expressions
    if (current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "CAST" || current_token_->value == "cast")) {
        return parse_cast_expression();
    }
    
    // Handle EXTRACT expressions
    if (current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "EXTRACT" || current_token_->value == "extract")) {
        return parse_extract_expression();
    }
    
    // Handle unary operators (NOT, EXISTS, -, +)
    if (current_token_->type == tokenizer::TokenType::Keyword) {
        if (current_token_->value == "NOT" || current_token_->value == "not") {
            // Check for NOT EXISTS
            advance(); // consume NOT
            
            if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                (current_token_->value == "EXISTS" || current_token_->value == "exists")) {
                // NOT EXISTS
                auto* exists_node = arena_.allocate<ast::ASTNode>();
                new (exists_node) ast::ASTNode(ast::NodeType::UnaryExpr);
                exists_node->node_id = next_node_id_++;
                exists_node->primary_text = "EXISTS";
                exists_node->semantic_flags |= 0x40; // Set NOT flag
                
                advance(); // consume EXISTS
                
                // Parse subquery
                auto* operand = parse_primary_expression();
                if (operand) {
                    operand->parent = exists_node;
                    exists_node->first_child = operand;
                    exists_node->child_count = 1;
                }
                return exists_node;
            } else {
                // Regular NOT
                auto* not_node = arena_.allocate<ast::ASTNode>();
                new (not_node) ast::ASTNode(ast::NodeType::UnaryExpr);
                not_node->node_id = next_node_id_++;
                not_node->primary_text = "NOT";
                
                // Parse operand with higher precedence than NOT (3)
                auto* operand = parse_expression(3);
                if (operand) {
                    operand->parent = not_node;
                    not_node->first_child = operand;
                    not_node->child_count = 1;
                }
                return not_node;
            }
        } else if (current_token_->value == "EXISTS" || current_token_->value == "exists") {
            // EXISTS without NOT
            auto* exists_node = arena_.allocate<ast::ASTNode>();
            new (exists_node) ast::ASTNode(ast::NodeType::UnaryExpr);
            exists_node->node_id = next_node_id_++;
            exists_node->primary_text = "EXISTS";
            
            advance(); // consume EXISTS
            
            // Parse subquery
            auto* operand = parse_primary_expression();
            if (operand) {
                operand->parent = exists_node;
                exists_node->first_child = operand;
                exists_node->child_count = 1;
            }
            return exists_node;
        }
    }
    
    // Handle unary - or +
    if (current_token_->type == tokenizer::TokenType::Operator &&
        (current_token_->value == "-" || current_token_->value == "+")) {
        // Save operator
        std::string_view op = current_token_->value;
        
        // Look ahead - if next is a number, we might combine them
        if (peek_token_ && peek_token_->type == tokenizer::TokenType::Number && op == "-") {
            // For negative numbers, just parse as number with minus
            advance(); // consume -
            auto* num = arena_.allocate<ast::ASTNode>();
            new (num) ast::ASTNode(ast::NodeType::IntegerLiteral);
            num->node_id = next_node_id_++;
            
            // Combine - with number
            std::string combined = "-";
            combined += std::string(current_token_->value);
            num->primary_text = copy_to_arena(combined);
            advance();
            return num;
        }
        
        // Otherwise, create unary expression
        auto* unary_node = arena_.allocate<ast::ASTNode>();
        new (unary_node) ast::ASTNode(ast::NodeType::UnaryExpr);
        unary_node->node_id = next_node_id_++;
        
        // Store operator
        unary_node->primary_text = copy_to_arena(op);
        
        advance(); // consume operator
        
        // Parse operand
        auto* operand = parse_primary_expression();
        if (operand) {
            operand->parent = unary_node;
            unary_node->first_child = operand;
            unary_node->child_count = 1;
        }
        return unary_node;
    }
    
    // Handle numbers
    if (current_token_->type == tokenizer::TokenType::Number) {
        auto* num = arena_.allocate<ast::ASTNode>();
        new (num) ast::ASTNode(ast::NodeType::IntegerLiteral);
        num->node_id = next_node_id_++;
        
        num->primary_text = copy_to_arena(current_token_->value);
        advance();
        return num;
    }
    
    // Handle strings
    if (current_token_->type == tokenizer::TokenType::String) {
        auto* str_node = arena_.allocate<ast::ASTNode>();
        new (str_node) ast::ASTNode(ast::NodeType::StringLiteral);
        str_node->node_id = next_node_id_++;
        
        str_node->primary_text = copy_to_arena(current_token_->value);
        advance();
        return str_node;
    }
    
    // Handle parentheses (could be subquery or grouped expression)
    if (current_token_->type == tokenizer::TokenType::Delimiter &&
        current_token_->value == "(") {
        parenthesis_depth_++;  // Track opening parenthesis
        advance(); // consume '('
        
        // Check if it's a SELECT subquery
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
            (current_token_->value == "SELECT" || current_token_->value == "select")) {
            // It's a subquery
            auto* subquery_node = arena_.allocate<ast::ASTNode>();
            new (subquery_node) ast::ASTNode(ast::NodeType::Subquery);
            subquery_node->node_id = next_node_id_++;
            
            // Parse the SELECT statement
            auto* select_stmt = parse_select_stmt();
            if (select_stmt) {
                select_stmt->parent = subquery_node;
                subquery_node->first_child = select_stmt;
                subquery_node->child_count = 1;
            }
            
            // Consume closing ')'
            if (current_token_ && current_token_->value == ")") {
                if (parenthesis_depth_ > 0) parenthesis_depth_--;
                advance();
            }
            
            return subquery_node;
        } else {
            // It's a grouped expression
            auto* expr = parse_expression(0);
            
            // Consume closing ')'
            if (current_token_ && current_token_->value == ")") {
                if (parenthesis_depth_ > 0) parenthesis_depth_--;
                advance();
            }
            
            return expr;
        }
    }
    
    // Handle special keyword literals (TRUE, FALSE, NULL)
    if (current_token_->type == tokenizer::TokenType::Keyword) {
        const auto& kw = current_token_->value;
        if (kw == "TRUE" || kw == "true" || kw == "FALSE" || kw == "false") {
            auto* bool_node = arena_.allocate<ast::ASTNode>();
            new (bool_node) ast::ASTNode(ast::NodeType::BooleanLiteral);
            bool_node->node_id = next_node_id_++;
            bool_node->primary_text = copy_to_arena(current_token_->value);
            advance();
            return bool_node;
        } else if (kw == "NULL" || kw == "null") {
            auto* null_node = arena_.allocate<ast::ASTNode>();
            new (null_node) ast::ASTNode(ast::NodeType::NullLiteral);
            null_node->node_id = next_node_id_++;
            null_node->primary_text = copy_to_arena("NULL");
            advance();
            return null_node;
        }
    }
    
    // Handle identifiers (could be column, function, or simple identifier)
    // Also handle keywords that can be used as identifiers (e.g., date, time, level)
    if (current_token_->type == tokenizer::TokenType::Identifier ||
        current_token_->type == tokenizer::TokenType::Keyword) {
        // Look ahead using peek_token_
        if (peek_token_) {
            // Check for function call
            if (peek_token_->type == tokenizer::TokenType::Delimiter &&
                peek_token_->value == "(") {
                return parse_function_call();
            }
            
            // Check for qualified name
            // Note: The tokenizer might classify "." as Operator, not Delimiter
            if ((peek_token_->type == tokenizer::TokenType::Delimiter ||
                 peek_token_->type == tokenizer::TokenType::Operator) &&
                peek_token_->value == ".") {
                return parse_column_ref();
            }
        }
        
        // Create identifier node for unqualified names
        // While semantically these are often column references,
        // we use Identifier for backward compatibility
        auto* id_node = arena_.allocate<ast::ASTNode>();
        new (id_node) ast::ASTNode(ast::NodeType::Identifier);
        id_node->node_id = next_node_id_++;
        id_node->primary_text = copy_to_arena(current_token_->value);
        advance();
        return id_node;
    }
    
    // Handle parenthesized expressions
    if (current_token_->type == tokenizer::TokenType::Delimiter &&
        current_token_->value == "(") {
        parenthesis_depth_++;
        advance(); // consume '('
        auto* expr = parse_expression(0);
        if (current_token_ && current_token_->value == ")") {
            if (parenthesis_depth_ > 0) parenthesis_depth_--;
            advance(); // consume ')'
        }
        return expr;
    }
    
    return nullptr;
}

// ========== Precedence Table ==========

int Parser::get_precedence() const {
    if (!current_token_) return 0;
    
    // Handle operators
    if (current_token_->type == tokenizer::TokenType::Operator) {
        const auto& op = current_token_->value;
        // Don't treat comma or dot as binary operators in expressions
        if (op == "," || op == ".") return 0;
        
        // Bitwise operators (lowest precedence after logical)
        if (op == "|") return 2;   // Bitwise OR (lower than concat)
        if (op == "&") return 2;   // Bitwise AND
        if (op == "^") return 2;   // Bitwise XOR
        if (op == "<<" || op == ">>") return 2;  // Bit shifts
        
        // String concatenation
        if (op == "||") return 3;  // String concatenation (lower than comparison)
        
        // Comparison operators
        if (op == "=") return 4;  // PREC_COMP
        if (op == "<" || op == ">") return 4;  // PREC_COMP
        if (op == "<=" || op == ">=") return 4;  // PREC_COMP
        if (op == "<>" || op == "!=") return 4;  // PREC_COMP
        
        // Arithmetic operators
        if (op == "+" || op == "-") return 5;  // PREC_TERM
        if (op == "*" || op == "/" || op == "%") return 6;  // PREC_FACTOR
        
        // Check for invalid operators (from other languages)
        if (op == "==" || op == "===" || op == "!==") {
            if (strict_mode_) {
                return -1;  // Invalid operator - will cause parse to fail
            }
            // In non-strict mode, treat as non-operator
            return 0;
        }
        
        // Unknown operator token - treat as non-operator
        return 0;
    }
    
    // Handle keywords that act as operators (only in WHERE/HAVING context)
    if (current_token_->type == tokenizer::TokenType::Keyword) {
        const auto& kw = current_token_->value;
        // SQL clause keywords should not be treated as operators
        if (kw == "FROM" || kw == "from" ||
            kw == "WHERE" || kw == "where" ||
            kw == "ORDER" || kw == "order" ||
            kw == "GROUP" || kw == "group" ||
            kw == "HAVING" || kw == "having" ||
            kw == "LIMIT" || kw == "limit" ||
            kw == "OFFSET" || kw == "offset") {
            return 0;  // Stop parsing expression
        }
        // Binary operators
        if (kw == "OR" || kw == "or") return 1;  // PREC_OR
        if (kw == "AND" || kw == "and") return 2;  // PREC_AND
        // SQL-specific operators (higher than AND but lower than comparison)
        if (kw == "BETWEEN" || kw == "between") return 3;  // PREC_BETWEEN
        if (kw == "IN" || kw == "in") return 3;  // PREC_IN
        if (kw == "LIKE" || kw == "like") return 3;  // PREC_LIKE
        if (kw == "IS" || kw == "is") return 3;  // PREC_IS (for IS NULL)
        // NOT can be binary when followed by LIKE/IN/BETWEEN
        if (kw == "NOT" || kw == "not") {
            // Look ahead to see if it's NOT LIKE/IN/BETWEEN
            if (peek_token_ && peek_token_->type == tokenizer::TokenType::Keyword) {
                const auto& next = peek_token_->value;
                if (next == "LIKE" || next == "like" ||
                    next == "IN" || next == "in" ||
                    next == "BETWEEN" || next == "between") {
                    return 3;  // Same precedence as LIKE/IN/BETWEEN
                }
            }
            return 0;  // Otherwise NOT is not a binary operator here
        }
    }
    
    return 0;  // No precedence
}

// ========== Pratt Parser for Expressions ==========

ast::ASTNode* Parser::parse_expression(int min_precedence) {
    DepthGuard guard(this);  // Protect against deep recursion
    if (!guard.is_valid()) return nullptr;
    
    // Pratt parser with proper precedence handling
    
    // Prefetch upcoming tokens for expression parsing
    // Expression parsing often examines multiple tokens ahead
    if (tokenizer_) {
        const auto& tokens = tokenizer_->get_tokens();
        size_t pos = tokenizer_->position();
        
        // Prefetch next 4 tokens for operator precedence checking
        if (pos + 1 < tokens.size()) __builtin_prefetch(&tokens[pos + 1], 0, 3);
        if (pos + 2 < tokens.size()) __builtin_prefetch(&tokens[pos + 2], 0, 2);
        if (pos + 3 < tokens.size()) __builtin_prefetch(&tokens[pos + 3], 0, 1);
        if (pos + 4 < tokens.size()) __builtin_prefetch(&tokens[pos + 4], 0, 1);
    }
    
    // Parse left side (primary expression)
    ast::ASTNode* left = parse_primary_expression();
    
    if (!left) {
        return nullptr;
    }
    
    // Loop to handle operators with precedence
    while (true) {
        int precedence = get_precedence();
        
        // Check for invalid operators in strict mode
        if (strict_mode_ && precedence == -1) {
            // Invalid operator detected
            return nullptr;  // Fail the parse
        }
        
        if (precedence < min_precedence) {
            break;  // Current operator has lower precedence
        }
        
        // Special case: precedence 0 means stop parsing (not an expression operator)
        if (precedence == 0) {
            break;
        }
        
        // Save operator info
        std::string_view op_value = current_token_->value;
        auto token_type = current_token_->type;
        
        // Handle special SQL operators
        bool has_not = false;
        if (token_type == tokenizer::TokenType::Keyword) {
            // Check for NOT prefix for LIKE, IN, BETWEEN
            if (op_value == "NOT" || op_value == "not") {
                // NOT in binary position - must be followed by LIKE, IN, or BETWEEN
                advance(); // consume NOT
                
                if (!current_token_ || current_token_->type != tokenizer::TokenType::Keyword) {
                    // NOT followed by non-keyword - this is an error
                    return left;
                }
                
                const auto& next_op = current_token_->value;
                if (next_op != "LIKE" && next_op != "like" &&
                    next_op != "IN" && next_op != "in" &&
                    next_op != "BETWEEN" && next_op != "between") {
                    // NOT followed by unsupported keyword - error
                    return left;
                }
                
                // Valid NOT LIKE/IN/BETWEEN
                has_not = true;
                op_value = current_token_->value;
            }
        }
        
        // Copy operator to arena
        std::string_view op_str_view = copy_to_arena(op_value);
        
        advance(); // consume operator (or the actual operator after NOT)
        
        // Handle special SQL operators
        if (token_type == tokenizer::TokenType::Keyword) {
            // BETWEEN x AND y (or NOT BETWEEN x AND y)
            if (op_value == "BETWEEN" || op_value == "between") {
                auto* lower = parse_expression(precedence + 1);
                if (!lower) return left;
                
                // Expect AND
                if (!current_token_ || current_token_->type != tokenizer::TokenType::Keyword ||
                    (current_token_->value != "AND" && current_token_->value != "and")) {
                    return left; // Error: missing AND
                }
                advance(); // consume AND
                
                auto* upper = parse_expression(precedence + 1);
                if (!upper) return left;
                
                // Create BETWEEN node
                auto* between_node = arena_.allocate<ast::ASTNode>();
                new (between_node) ast::ASTNode(ast::NodeType::BetweenExpr);
                between_node->node_id = next_node_id_++;
                
                // Store "BETWEEN" or "NOT BETWEEN"
                if (has_not) {
                    between_node->primary_text = copy_to_arena("NOT BETWEEN");
                    between_node->semantic_flags |= (1 << 6); // Use bit 6 for NOT flag
                } else {
                    between_node->primary_text = op_str_view;
                }
                
                // Children: left, lower, upper
                left->parent = between_node;
                between_node->first_child = left;
                between_node->child_count = 1;
                
                lower->parent = between_node;
                left->next_sibling = lower;
                between_node->child_count = 2;
                
                upper->parent = between_node;
                lower->next_sibling = upper;
                between_node->child_count = 3;
                
                left = between_node;
                continue;
            }
            
            // IN (list) or IN (subquery) or NOT IN ...
            if (op_value == "IN" || op_value == "in") {
                // Check if next is a subquery or a list
                ast::ASTNode* in_operand = nullptr;
                
                // Look for opening paren
                if (current_token_ && current_token_->value == "(") {
                    // Peek ahead to see if it's a SELECT
                    if (peek_token_ && peek_token_->type == tokenizer::TokenType::Keyword &&
                        (peek_token_->value == "SELECT" || peek_token_->value == "select")) {
                        // It's a subquery - parse it as a primary expression
                        in_operand = parse_primary_expression();
                    } else {
                        // It's a list - parse it here
                        parenthesis_depth_++;
                        advance(); // consume (
                        
                        auto* in_node = arena_.allocate<ast::ASTNode>();
                        new (in_node) ast::ASTNode(ast::NodeType::InExpr);
                        in_node->node_id = next_node_id_++;
                        
                        // Store "IN" or "NOT IN"
                        if (has_not) {
                            in_node->primary_text = copy_to_arena("NOT IN");
                            in_node->semantic_flags |= (1 << 6); // Use bit 6 for NOT flag
                        } else {
                            in_node->primary_text = op_str_view;
                        }
                        
                        // Left operand
                        left->parent = in_node;
                        in_node->first_child = left;
                        in_node->child_count = 1;
                        
                        // Parse list items
                        ast::ASTNode* last_item = left;
                        while (current_token_ && current_token_->value != ")") {
                            auto* item = parse_expression(0);
                            if (item) {
                                item->parent = in_node;
                                last_item->next_sibling = item;
                                last_item = item;
                                in_node->child_count++;
                            }
                            
                            if (current_token_ && current_token_->value == ",") {
                                advance(); // consume comma
                            } else if (current_token_ && current_token_->value != ")") {
                                break; // Error in list
                            }
                        }
                        
                        if (current_token_ && current_token_->value == ")") {
                            if (parenthesis_depth_ > 0) parenthesis_depth_--;
                            advance(); // consume )
                        }
                        
                        left = in_node;
                        continue;
                    }
                }
                
                // If we have a subquery, create IN node with subquery
                if (in_operand && in_operand->node_type == ast::NodeType::Subquery) {
                    auto* in_node = arena_.allocate<ast::ASTNode>();
                    new (in_node) ast::ASTNode(ast::NodeType::InExpr);
                    in_node->node_id = next_node_id_++;
                    
                    // Store "IN" or "NOT IN"
                    if (has_not) {
                        in_node->primary_text = copy_to_arena("NOT IN");
                        in_node->semantic_flags |= (1 << 6); // Use bit 6 for NOT flag
                    } else {
                        in_node->primary_text = op_str_view;
                    }
                    
                    // Left operand
                    left->parent = in_node;
                    in_node->first_child = left;
                    in_node->child_count = 1;
                    
                    // Subquery as second child
                    in_operand->parent = in_node;
                    left->next_sibling = in_operand;
                    in_node->child_count = 2;
                    
                    left = in_node;
                    continue;
                }
                
                // If neither list nor subquery was parsed properly, just continue
                continue;
            }
            
            // LIKE pattern or NOT LIKE pattern
            if (op_value == "LIKE" || op_value == "like") {
                auto* pattern = parse_expression(precedence + 1);
                if (!pattern) return left;
                
                auto* like_node = arena_.allocate<ast::ASTNode>();
                new (like_node) ast::ASTNode(ast::NodeType::LikeExpr);
                like_node->node_id = next_node_id_++;
                
                // Store "LIKE" or "NOT LIKE"
                if (has_not) {
                    like_node->primary_text = copy_to_arena("NOT LIKE");
                    like_node->semantic_flags |= (1 << 6); // Use bit 6 for NOT flag
                } else {
                    like_node->primary_text = op_str_view;
                }
                
                left->parent = like_node;
                like_node->first_child = left;
                like_node->child_count = 1;
                
                pattern->parent = like_node;
                left->next_sibling = pattern;
                like_node->child_count = 2;
                
                left = like_node;
                continue;
            }
            
            // IS NULL / IS NOT NULL
            if (op_value == "IS" || op_value == "is") {
                bool is_not = false;
                
                // Check for NOT
                if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
                    (current_token_->value == "NOT" || current_token_->value == "not")) {
                    is_not = true;
                    advance(); // consume NOT
                }
                
                // Expect NULL
                if (!current_token_ || current_token_->type != tokenizer::TokenType::Keyword ||
                    (current_token_->value != "NULL" && current_token_->value != "null")) {
                    return left; // Error: expected NULL
                }
                advance(); // consume NULL
                
                auto* is_null_node = arena_.allocate<ast::ASTNode>();
                new (is_null_node) ast::ASTNode(ast::NodeType::IsNullExpr);
                is_null_node->node_id = next_node_id_++;
                
                // Store IS NULL or IS NOT NULL
                is_null_node->primary_text = copy_to_arena(is_not ? "IS NOT NULL" : "IS NULL");
                
                left->parent = is_null_node;
                is_null_node->first_child = left;
                is_null_node->child_count = 1;
                
                left = is_null_node;
                continue;
            }
        }
        
        // Check for ANY/ALL/SOME after comparison operators
        bool has_any_all = false;
        std::string modifier;
        
        if ((op_value == "=" || op_value == "<" || op_value == ">" || 
             op_value == "<=" || op_value == ">=" || op_value == "<>" || op_value == "!=") &&
            current_token_ && (current_token_->type == tokenizer::TokenType::Keyword ||
                              current_token_->type == tokenizer::TokenType::Identifier)) {
            
            const auto& kw = current_token_->value;
            if (kw == "ANY" || kw == "any" || kw == "SOME" || kw == "some") {
                has_any_all = true;
                modifier = " ANY";
                advance(); // consume ANY/SOME
            } else if (kw == "ALL" || kw == "all") {
                has_any_all = true;
                modifier = " ALL";
                advance(); // consume ALL
            }
        }
        
        // Standard binary operator
        ast::ASTNode* right = parse_expression(precedence + 1);
        
        if (!right) {
            // If we can't parse right side, it might be an error
            // For now, just return what we have
            return left;
        }
        
        // Create binary expression node
        auto* binary_node = arena_.allocate<ast::ASTNode>();
        new (binary_node) ast::ASTNode(ast::NodeType::BinaryExpr);
        binary_node->node_id = next_node_id_++;
        
        // Store operator with ANY/ALL modifier if present
        if (has_any_all) {
            std::string op_with_modifier = std::string(op_str_view) + modifier;
            binary_node->primary_text = copy_to_arena(op_with_modifier);
        } else {
            binary_node->primary_text = op_str_view; // Store operator
        }
        
        // Set up the binary expression tree
        left->parent = binary_node;
        binary_node->first_child = left;
        binary_node->child_count = 1;
        
        right->parent = binary_node;
        left->next_sibling = right;
        binary_node->child_count = 2;
        
        // The binary node becomes the new left for the next iteration
        left = binary_node;
    }
    
    return left;
}

ast::ASTNode* Parser::parse_case_expression() {
    // Parse CASE expressions:
    // CASE [expr] WHEN condition THEN result [WHEN...] [ELSE result] END
    
    advance(); // consume CASE
    
    auto* case_node = arena_.allocate<ast::ASTNode>();
    new (case_node) ast::ASTNode(ast::NodeType::CaseExpr);
    case_node->node_id = next_node_id_++;
    
    ast::ASTNode* last_child = nullptr;
    ast::ASTNode* search_expr = nullptr;
    
    // Check if this is a searched CASE (has expression after CASE)
    if ((current_token_ && current_token_->type != tokenizer::TokenType::Keyword) ||
        (current_token_->value != "WHEN" && current_token_->value != "when")) {
        // Parse the search expression
        search_expr = parse_expression(0);
        if (search_expr) {
            search_expr->parent = case_node;
            case_node->first_child = search_expr;
            case_node->child_count++;
            last_child = search_expr;
        }
    }
    
    // Parse WHEN clauses
    while (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
           (current_token_->value == "WHEN" || current_token_->value == "when")) {
        advance(); // consume WHEN
        
        // Create a WHEN node (using BinaryExpr with "WHEN" as operator)
        auto* when_node = arena_.allocate<ast::ASTNode>();
        new (when_node) ast::ASTNode(ast::NodeType::BinaryExpr);
        when_node->node_id = next_node_id_++;
        
        // Store "WHEN" as operator
        when_node->primary_text = copy_to_arena("WHEN");
        
        // Parse condition
        auto* condition = parse_expression(0);
        
        // Expect THEN
        if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
            (current_token_->value == "THEN" || current_token_->value == "then")) {
            advance(); // consume THEN
            
            // Parse result expression
            auto* result = parse_expression(0);
            
            // Set up WHEN node with condition and result as children
            if (condition) {
                condition->parent = when_node;
                when_node->first_child = condition;
                when_node->child_count++;
            }
            if (result) {
                result->parent = when_node;
                if (condition) {
                    condition->next_sibling = result;
                } else {
                    when_node->first_child = result;
                }
                when_node->child_count++;
            }
        }
        
        // Add WHEN node to CASE
        when_node->parent = case_node;
        if (!case_node->first_child) {
            case_node->first_child = when_node;
        } else if (last_child) {
            last_child->next_sibling = when_node;
        }
        last_child = when_node;
        case_node->child_count++;
    }
    
    // Parse optional ELSE clause
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "ELSE" || current_token_->value == "else")) {
        advance(); // consume ELSE
        
        auto* else_result = parse_expression(0);
        if (else_result) {
            else_result->parent = case_node;
            if (last_child) {
                last_child->next_sibling = else_result;
            } else {
                case_node->first_child = else_result;
            }
            case_node->child_count++;
        }
    }
    
    // Expect END
    if (current_token_ && current_token_->type == tokenizer::TokenType::Keyword &&
        (current_token_->value == "END" || current_token_->value == "end")) {
        advance(); // consume END
    }
    
    return case_node;
}

// ========== CAST Expression Parser ==========

ast::ASTNode* Parser::parse_cast_expression() {
    // Parse CAST(expression AS type)
    
    advance(); // consume CAST
    
    // Expect opening parenthesis
    if (!current_token_ || current_token_->value != "(") {
        return nullptr;
    }
    advance(); // consume (
    
    auto* cast_node = arena_.allocate<ast::ASTNode>();
    new (cast_node) ast::ASTNode(ast::NodeType::CastExpr);
    cast_node->node_id = next_node_id_++;
    cast_node->primary_text = copy_to_arena("CAST");
    
    // Parse the expression to cast
    auto* expr = parse_expression(0);
    if (!expr) {
        return nullptr;
    }
    
    // Expect AS keyword
    if (!current_token_ || current_token_->type != tokenizer::TokenType::Keyword ||
        (current_token_->value != "AS" && current_token_->value != "as")) {
        return nullptr;
    }
    advance(); // consume AS
    
    // Parse the target data type
    ast::ASTNode* type_node = nullptr;
    if (current_token_ && (current_token_->type == tokenizer::TokenType::Identifier ||
                           current_token_->type == tokenizer::TokenType::Keyword)) {
        type_node = arena_.allocate<ast::ASTNode>();
        new (type_node) ast::ASTNode(ast::NodeType::Identifier);
        type_node->node_id = next_node_id_++;
        type_node->primary_text = copy_to_arena(current_token_->value);
        advance();
        
        // Check for type parameters like VARCHAR(100)
        if (current_token_ && current_token_->value == "(") {
            advance(); // consume (
            
            // Consume type parameters
            int paren_depth = 1;
            std::string type_params;
            while (current_token_ && paren_depth > 0) {
                if (current_token_->value == "(") {
                    paren_depth++;
                } else if (current_token_->value == ")") {
                    paren_depth--;
                    if (paren_depth == 0) break;
                }
                type_params += std::string(current_token_->value);
                advance();
            }
            
            if (current_token_ && current_token_->value == ")") {
                advance(); // consume final )
            }
            
            // Store type parameters
            if (!type_params.empty()) {
                type_node->schema_name = copy_to_arena(type_params);
            }
        }
    }
    
    // Expect closing parenthesis
    if (!current_token_ || current_token_->value != ")") {
        return nullptr;
    }
    advance(); // consume )
    
    // Set up children: expression and type
    expr->parent = cast_node;
    cast_node->first_child = expr;
    cast_node->child_count = 1;
    
    if (type_node) {
        type_node->parent = cast_node;
        expr->next_sibling = type_node;
        cast_node->child_count = 2;
    }
    
    return cast_node;
}

// ========== EXTRACT Expression Parser ==========

ast::ASTNode* Parser::parse_extract_expression() {
    // Parse EXTRACT(temporal_part FROM temporal_expression)
    // temporal_part: YEAR, MONTH, DAY, HOUR, MINUTE, SECOND, etc.
    
    advance(); // consume EXTRACT
    
    // Expect opening parenthesis
    if (!current_token_ || current_token_->value != "(") {
        return nullptr;
    }
    advance(); // consume (
    
    auto* extract_node = arena_.allocate<ast::ASTNode>();
    new (extract_node) ast::ASTNode(ast::NodeType::FunctionCall);
    extract_node->node_id = next_node_id_++;
    extract_node->primary_text = copy_to_arena("EXTRACT");
    
    // Parse temporal part (YEAR, MONTH, DAY, etc.)
    // These could be keywords or identifiers
    ast::ASTNode* temporal_part = nullptr;
    if (current_token_ && (current_token_->type == tokenizer::TokenType::Identifier ||
                           current_token_->type == tokenizer::TokenType::Keyword)) {
        temporal_part = arena_.allocate<ast::ASTNode>();
        new (temporal_part) ast::ASTNode(ast::NodeType::Identifier);
        temporal_part->node_id = next_node_id_++;
        temporal_part->primary_text = copy_to_arena(current_token_->value);
        advance();
    } else {
        return nullptr; // Expected temporal part
    }
    
    // Expect FROM keyword
    if (!current_token_ || current_token_->type != tokenizer::TokenType::Keyword ||
        (current_token_->value != "FROM" && current_token_->value != "from")) {
        return nullptr;
    }
    advance(); // consume FROM
    
    // Parse the temporal expression
    // Since FROM was already consumed, we can parse normally
    ast::ASTNode* temporal_expr = nullptr;
    
    // Parse expression until closing parenthesis
    // Most commonly this is a column reference or simple expression
    if (current_token_ && current_token_->value != ")") {
        // Check if it's a simple identifier/column
        if (current_token_->type == tokenizer::TokenType::Identifier) {
            // Check for qualified column (table.column)
            if (peek_token_ && peek_token_->value == ".") {
                temporal_expr = parse_column_ref();
            } else {
                // Unqualified column reference
                auto* col_ref = arena_.allocate<ast::ASTNode>();
                new (col_ref) ast::ASTNode(ast::NodeType::ColumnRef);
                col_ref->node_id = next_node_id_++;
                col_ref->primary_text = copy_to_arena(current_token_->value);
                advance();
                temporal_expr = col_ref;
            }
        } else if (current_token_->type == tokenizer::TokenType::Keyword) {
            // Some keywords can be column names
            auto* col_ref = arena_.allocate<ast::ASTNode>();
            new (col_ref) ast::ASTNode(ast::NodeType::ColumnRef);
            col_ref->node_id = next_node_id_++;
            col_ref->primary_text = copy_to_arena(current_token_->value);
            advance();
            temporal_expr = col_ref;
        } else if (current_token_->value == "(") {
            // Could be a nested expression or function
            temporal_expr = parse_primary_expression();
        } else {
            // Try to parse as a general expression
            // But we need to be careful about stopping at the closing paren
            temporal_expr = parse_primary_expression();
        }
    }
    
    // Expect closing parenthesis
    if (!current_token_ || current_token_->value != ")") {
        return nullptr;
    }
    advance(); // consume )
    
    // Set up children: temporal_part and temporal_expression
    if (temporal_part) {
        temporal_part->parent = extract_node;
        extract_node->first_child = temporal_part;
        extract_node->child_count = 1;
    }
    
    if (temporal_expr) {
        temporal_expr->parent = extract_node;
        if (temporal_part) {
            temporal_part->next_sibling = temporal_expr;
        } else {
            extract_node->first_child = temporal_expr;
        }
        extract_node->child_count++;
    }
    
    return extract_node;
}

ast::ASTNode* Parser::parse_primary() {
    // TODO: Implement primary expression parsing
    return nullptr;
}


// ========== Error Handling ==========

[[noreturn]] void Parser::error(const std::string& message) {
    // Since we have exceptions disabled, use abort for fatal errors
    // In production, this should set an error state instead
    (void)message;  // Suppress unused warning
    std::abort();   // Fatal error - parser is in invalid state
}

void Parser::synchronize() {
    // TODO: Error recovery - skip to next statement boundary
}

// ========== Validation Methods ==========

bool Parser::validate_ast(ast::ASTNode* root) {
    if (!root) return false;
    
    // Dispatch based on statement type
    switch (root->node_type) {
        case ast::NodeType::SelectStmt:
            return validate_select_stmt(root);
        case ast::NodeType::UnionStmt:
        case ast::NodeType::IntersectStmt:
        case ast::NodeType::ExceptStmt:
            // For set operations, validate both sides
            if (root->first_child) {
                if (!validate_ast(root->first_child)) return false;
                if (root->first_child->next_sibling) {
                    return validate_ast(root->first_child->next_sibling);
                }
            }
            return true;
        case ast::NodeType::InsertStmt:
        case ast::NodeType::UpdateStmt:
        case ast::NodeType::DeleteStmt:
            // Basic validation for DML statements
            return true;  // TODO: Add specific validation
        default:
            return true;  // Unknown statement types pass for now
    }
}

bool Parser::validate_select_stmt(ast::ASTNode* select_stmt) {
    if (!select_stmt || select_stmt->node_type != ast::NodeType::SelectStmt) {
        return false;
    }
    
    // Check clause dependencies
    if (!validate_clause_dependencies(select_stmt)) {
        return false;
    }
    
    // Validate JOIN clauses if present
    const ast::ASTNode* child = select_stmt->first_child;
    while (child) {
        if (child->node_type == ast::NodeType::FromClause) {
            // Check JOINs within FROM clause
            ast::ASTNode* from_child = child->first_child;
            while (from_child) {
                if (from_child->node_type == ast::NodeType::JoinClause) {
                    if (!validate_join_clause(from_child)) {
                        return false;
                    }
                }
                from_child = from_child->next_sibling;
            }
        }
        child = child->next_sibling;
    }
    
    return true;
}

bool Parser::validate_clause_dependencies(ast::ASTNode* select_stmt) {
    bool has_from = false;
    bool has_where = false;
    bool has_group_by = false;
    bool has_having = false;
    bool has_order_by = false;
    
    // Scan all clauses
    ast::ASTNode* child = select_stmt->first_child;
    while (child) {
        switch (child->node_type) {
            case ast::NodeType::FromClause:
                has_from = true;
                break;
            case ast::NodeType::WhereClause:
                has_where = true;
                break;
            case ast::NodeType::GroupByClause:
                has_group_by = true;
                break;
            case ast::NodeType::HavingClause:
                has_having = true;
                break;
            case ast::NodeType::OrderByClause:
                has_order_by = true;
                break;
            default:
                break;
        }
        child = child->next_sibling;
    }
    
    // Validate dependencies
    // WHERE, GROUP BY, HAVING, ORDER BY all require FROM
    if ((has_where || has_group_by || has_having || has_order_by) && !has_from) {
        return false;  // These clauses require FROM
    }
    
    // HAVING without GROUP BY is semantically questionable but syntactically valid
    // Some databases allow it (treats whole result as one group)
    // So we don't enforce this dependency at parse time
    // if (has_having && !has_group_by) {
    //     return false;
    // }
    
    return true;
}

bool Parser::validate_join_clause(ast::ASTNode* join_clause) {
    if (!join_clause || join_clause->node_type != ast::NodeType::JoinClause) {
        return false;
    }
    
    // JOIN must have at least a table reference as first child
    if (!join_clause->first_child) {
        return false;  // JOIN without table is invalid
    }
    
    // First child should be a table reference or subquery
    ast::ASTNode* table_ref = join_clause->first_child;
    if (table_ref->node_type != ast::NodeType::TableRef &&
        table_ref->node_type != ast::NodeType::Subquery) {
        return false;  // JOIN must specify a table or subquery
    }
    
    // If there's an ON clause, it should be the second child
    // (ON clause is optional for CROSS JOIN)
    if (join_clause->primary_text == "CROSS JOIN" || 
        join_clause->primary_text == "cross join") {
        return true;  // CROSS JOIN doesn't need ON clause
    }
    
    // Other JOINs should have ON clause (second child)
    if (!table_ref->next_sibling) {
        // Missing ON clause for non-CROSS JOIN
        // Allow it for now as some databases support NATURAL JOIN
        return true;
    }
    
    return true;
}

} // namespace db25::parser